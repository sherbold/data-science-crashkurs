{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f08551b-bd44-410c-918e-ecc1781966bf",
   "metadata": {},
   "source": [
    "## Übung zu Kapitel 11\n",
    "\n",
    "In dieser Übung wenden wir die eingeführten statistischen Methoden zum besseren Verständnis an. Hierzu vergleichen wir verschiedene Klassifikationsmodelle auf den [Irisdaten](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html). \n",
    "\n",
    "### Mehrfaches Training\n",
    "\n",
    "Erstellen Sie fünf zufällige Aufteilungen der Irisdaten in je 50% Trainingsdaten und 50% Testdaten. Trainieren Sie ein 5-Nearest-Neighbor-Modell und einen Random Forest (mit 100 Random Trees) für jede dieser Aufteilungen. Berechnen Sie die Güte für jedes dieser Modelle mit MCC und erstellen Sie für jedes Modell eine Liste mit den Ergebnissen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd241d8-9ae0-4ecc-949c-c0fe9cec9a7f",
   "metadata": {},
   "source": [
    "### Statistischer Vergleich\n",
    "\n",
    "Vergleichen Sie das arithmetische Mittel, die Standardabweichung, den Median, das Minimum und das Maximum des MCC für beide Algorithmen. Benutzen Sie geeignete statistische Tests, um zu bestimmen, ob der Unterschied signifikant ist. Falls der Unterschied signifikant ist, berechnen Sie Cohens $d$, um die Effektstärke zu bestimmen. Berechnen Sie außerdem das 95%-Konfidenzintervall des arithmetischen Mittels von MCC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cb452b-a742-4ee7-9410-3b48c82c6421",
   "metadata": {},
   "source": [
    "### Mehr Vergleiche\n",
    "\n",
    "Wiederholen Sie diese Auswertung mit 10, 50 und 100 zufälligen Aufteilungen der Irisdaten. Wie verändern sich die Ergebnisse?\n",
    "\n",
    "Der folgende Quelltext erledigt alle Aufgaben gleichzeitig. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a70edda4-19f2-41e8-9185-6902826ac008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "Schätze Güte von KNN und Random Forest mit 5 Train/Test Splits\n",
      "\n",
      "Random Forest: mean   = 0.9362 [0.9191,0.9533]\n",
      "               sd     = 0.0195\n",
      "               median = 0.9403\n",
      "               min    = 0.9002\n",
      "               max    = 0.9600\n",
      "KNN:           mean   = 0.9363 [0.9159,0.9567]\n",
      "               sd     = 0.0233\n",
      "               median = 0.9210\n",
      "               min    = 0.9200\n",
      "               max    = 0.9803\n",
      "\n",
      "p-value des Shapiro-Wilk test für den Random Forest:   0.1309\n",
      "Der Test ergibt das die Daten wahrscheinlich normalverteilt sind\n",
      "und wir können die Nullhypothese nicht ablehnen mit einem\n",
      "Signifikanzniveau von alpha=0.005\n",
      "\n",
      "p-value des Shapiro-Wilk test für KNN: 0.0262\n",
      "Der Test ergibt das die Daten wahrscheinlich normalverteilt sind\n",
      "und wir können die Nullhypothese nicht ablehnen mit einem\n",
      "Signifikanzniveau von alpha=0.005\n",
      "\n",
      "Beide Lösungen sind wahrscheinlich normalverteilt. Benutze\n",
      "Welch's t-test.\n",
      "\n",
      "p-value von Welch's t-test: 0.994890\n",
      "The Test ergibt, dass die Mittelwerte vermutlich gleich sind und\n",
      "wir können die Nullhypothese nicht ablehnen mit einem\n",
      "Signifikanzniveau von alpha=0.005\n",
      "----------------------------------------------------------------\n",
      "Schätze Güte von KNN und Random Forest mit 10 Train/Test Splits\n",
      "\n",
      "Random Forest: mean   = 0.9277 [0.9162,0.9393]\n",
      "               sd     = 0.0229\n",
      "               median = 0.9403\n",
      "               min    = 0.8838\n",
      "               max    = 0.9600\n",
      "KNN:           mean   = 0.9476 [0.9352,0.9600]\n",
      "               sd     = 0.0245\n",
      "               median = 0.9403\n",
      "               min    = 0.9200\n",
      "               max    = 0.9803\n",
      "\n",
      "p-value des Shapiro-Wilk test für den Random Forest:   0.0266\n",
      "Der Test ergibt das die Daten wahrscheinlich normalverteilt sind\n",
      "und wir können die Nullhypothese nicht ablehnen mit einem\n",
      "Signifikanzniveau von alpha=0.005\n",
      "\n",
      "p-value des Shapiro-Wilk test für KNN: 0.0079\n",
      "Der Test ergibt das die Daten wahrscheinlich normalverteilt sind\n",
      "und wir können die Nullhypothese nicht ablehnen mit einem\n",
      "Signifikanzniveau von alpha=0.005\n",
      "\n",
      "Beide Lösungen sind wahrscheinlich normalverteilt. Benutze\n",
      "Welch's t-test.\n",
      "\n",
      "p-value von Welch's t-test: 0.035402\n",
      "The Test ergibt, dass die Mittelwerte vermutlich gleich sind und\n",
      "wir können die Nullhypothese nicht ablehnen mit einem\n",
      "Signifikanzniveau von alpha=0.005\n",
      "----------------------------------------------------------------\n",
      "Schätze Güte von KNN und Random Forest mit 50 Train/Test Splits\n",
      "\n",
      "Random Forest: mean   = 0.9305 [0.9235,0.9374]\n",
      "               sd     = 0.0287\n",
      "               median = 0.9403\n",
      "               min    = 0.8658\n",
      "               max    = 0.9803\n",
      "KNN:           mean   = 0.9421 [0.9355,0.9487]\n",
      "               sd     = 0.0272\n",
      "               median = 0.9403\n",
      "               min    = 0.8482\n",
      "               max    = 1.0000\n",
      "\n",
      "p-value des Shapiro-Wilk test für den Random Forest:   0.0111\n",
      "Der Test ergibt das die Daten wahrscheinlich normalverteilt sind\n",
      "und wir können die Nullhypothese nicht ablehnen mit einem\n",
      "Signifikanzniveau von alpha=0.005\n",
      "\n",
      "p-value des Shapiro-Wilk test für KNN: 0.0021\n",
      "Der Test ergibt das die Daten wahrscheinlich nicht normalverteilt\n",
      "sind und wir lehnen die Nullhypothese ab mit einem\n",
      "Signifikanzniveau von alpha=0.005\n",
      "\n",
      "Mindestens eine Verteilung wahrscheinlich nicht normalverteilt.\n",
      "Benutze den Mann-Whitney-U Test.\n",
      "\n",
      "p-value vom Mann-Whitney-U Test: 0.024551\n",
      "The Test ergibt, dass die Mittelwerte vermutlich gleich sind und\n",
      "wir können die Nullhypothese nicht ablehnen mit einem\n",
      "Signifikanzniveau von alpha=0.005\n",
      "----------------------------------------------------------------\n",
      "Schätze Güte von KNN und Random Forest mit 100 Train/Test Splits\n",
      "\n",
      "Random Forest: mean   = 0.9300 [0.9259,0.9342]\n",
      "               sd     = 0.0271\n",
      "               median = 0.9403\n",
      "               min    = 0.8482\n",
      "               max    = 0.9803\n",
      "KNN:           mean   = 0.9392 [0.9352,0.9432]\n",
      "               sd     = 0.0265\n",
      "               median = 0.9403\n",
      "               min    = 0.8482\n",
      "               max    = 1.0000\n",
      "\n",
      "p-value des Shapiro-Wilk test für den Random Forest:   0.0000\n",
      "Der Test ergibt das die Daten wahrscheinlich nicht normalverteilt\n",
      "sind und wir lehnen die Nullhypothese ab mit einem\n",
      "Signifikanzniveau von alpha=0.005\n",
      "\n",
      "p-value des Shapiro-Wilk test für KNN: 0.0001\n",
      "Der Test ergibt das die Daten wahrscheinlich nicht normalverteilt\n",
      "sind und wir lehnen die Nullhypothese ab mit einem\n",
      "Signifikanzniveau von alpha=0.005\n",
      "\n",
      "Mindestens eine Verteilung wahrscheinlich nicht normalverteilt.\n",
      "Benutze den Mann-Whitney-U Test.\n",
      "\n",
      "p-value vom Mann-Whitney-U Test: 0.006746\n",
      "The Test ergibt, dass die Mittelwerte vermutlich gleich sind und\n",
      "wir können die Nullhypothese nicht ablehnen mit einem\n",
      "Signifikanzniveau von alpha=0.005\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy import stats\n",
    "from statistics import mean, stdev\n",
    "from math import sqrt\n",
    "from scipy.stats import norm\n",
    "from textwrap import TextWrapper\n",
    "\n",
    "wrapper = TextWrapper(width=65)\n",
    "\n",
    "\n",
    "def wrap_print(string):\n",
    "    print('\\n'.join(wrapper.wrap(string)))\n",
    "\n",
    "\n",
    "X, Y = load_iris(return_X_y=True)\n",
    "\n",
    "knn = KNeighborsClassifier(5)\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "scores_rf = []\n",
    "scores_knn = []\n",
    "for repetitions in [5, 10, 50, 100]:\n",
    "    wrap_print(\"----------------------------------------------------------------\")\n",
    "    wrap_print(\n",
    "        \"Schätze Güte von KNN und Random Forest mit %i Train/Test Splits\" % repetitions)\n",
    "    for i in range(0, repetitions):\n",
    "        # bootstrap loop\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "            X, Y, test_size=0.50, stratify=Y)\n",
    "        rf.fit(X_train, Y_train)\n",
    "        Y_pred = rf.predict(X_test)\n",
    "        scores_rf.append(matthews_corrcoef(Y_test, Y_pred))\n",
    "        knn.fit(X_train, Y_train)\n",
    "        Y_pred = knn.predict(X_test)\n",
    "        scores_knn.append(matthews_corrcoef(Y_test, Y_pred))\n",
    "\n",
    "    s1 = scores_rf\n",
    "    s2 = scores_knn\n",
    "\n",
    "    def calc_ci(mu, sd, n, cl):\n",
    "        dev = norm.ppf((1-cl)/2)*sd/sqrt(n)\n",
    "        return mu+dev, mu-dev\n",
    "\n",
    "    s1_lower, s1_upper = calc_ci(np.mean(s1), np.std(s1), len(s1), 0.95)\n",
    "    s2_lower, s2_upper = calc_ci(np.mean(s2), np.std(s2), len(s2), 0.95)\n",
    "\n",
    "    print()\n",
    "    print(\"Random Forest: mean   = %.4f [%.4f,%.4f]\" % (\n",
    "        np.mean(s1), s1_lower, s1_upper))\n",
    "    print(\"               sd     = %.4f\" % np.std(s1))\n",
    "    print(\"               median = %.4f\" % np.median(s1))\n",
    "    print(\"               min    = %.4f\" % np.min(s1))\n",
    "    print(\"               max    = %.4f\" % np.max(s1))\n",
    "    print(\"KNN:           mean   = %.4f [%.4f,%.4f]\" % (\n",
    "        np.mean(s2), s2_lower, s2_upper))\n",
    "    print(\"               sd     = %.4f\" % np.std(s2))\n",
    "    print(\"               median = %.4f\" % np.median(s2))\n",
    "    print(\"               min    = %.4f\" % np.min(s2))\n",
    "    print(\"               max    = %.4f\" % np.max(s2))\n",
    "    print()\n",
    "\n",
    "    alpha = 0.005\n",
    "    pval_shapiro1 = stats.shapiro(s1)[1]\n",
    "    pval_shapiro2 = stats.shapiro(s2)[1]\n",
    "\n",
    "    print('p-value des Shapiro-Wilk test für den Random Forest:   %.4f' %\n",
    "          pval_shapiro1)\n",
    "    if pval_shapiro1 > alpha:\n",
    "        wrap_print('Der Test ergibt das die Daten wahrscheinlich normalverteilt sind und wir können die Nullhypothese nicht ablehnen mit einem Signifikanzniveau von alpha=%.3f' % alpha)\n",
    "    else:\n",
    "        wrap_print('Der Test ergibt das die Daten wahrscheinlich nicht normalverteilt sind und wir lehnen die Nullhypothese ab mit einem Signifikanzniveau von alpha=%.3f' % alpha)\n",
    "\n",
    "    print()\n",
    "    print('p-value des Shapiro-Wilk test für KNN: %.4f' % pval_shapiro2)\n",
    "    if pval_shapiro2 > alpha:\n",
    "        wrap_print('Der Test ergibt das die Daten wahrscheinlich normalverteilt sind und wir können die Nullhypothese nicht ablehnen mit einem Signifikanzniveau von alpha=%.3f' % alpha)\n",
    "    else:\n",
    "        wrap_print('Der Test ergibt das die Daten wahrscheinlich nicht normalverteilt sind und wir lehnen die Nullhypothese ab mit einem Signifikanzniveau von alpha=%.3f' % alpha)\n",
    "        \n",
    "    print()\n",
    "\n",
    "    if pval_shapiro1 > alpha and pval_shapiro2 > alpha:\n",
    "        wrap_print(\"Beide Lösungen sind wahrscheinlich normalverteilt. Benutze Welch's t-test.\")\n",
    "        pval_equal = stats.ttest_ind(s1, s2, equal_var=False)[1]\n",
    "        print()\n",
    "        print(\"p-value von Welch's t-test: %f\" % pval_equal)\n",
    "    else:\n",
    "        wrap_print(\n",
    "            \"Mindestens eine Verteilung wahrscheinlich nicht normalverteilt. Benutze den Mann-Whitney-U Test.\")\n",
    "        pval_equal = stats.mannwhitneyu(s1, s2, alternative='two-sided')[1]\n",
    "        print()\n",
    "        print(\"p-value vom Mann-Whitney-U Test: %f\" % pval_equal)\n",
    "\n",
    "    if pval_equal > alpha:\n",
    "        wrap_print('The Test ergibt, dass die Mittelwerte vermutlich gleich sind und wir können die Nullhypothese nicht ablehnen mit einem Signifikanzniveau von alpha=%.3f' % alpha)\n",
    "    else:\n",
    "        wrap_print('The Test ergibt, dass die Mittelwerte vermutlich nicht gleich sind und wir lehnen die Nullhypothese ab mit einem Signifikanzniveau von alpha=%.3f' % alpha)\n",
    "        s = sqrt(((len(s1)-1)*stdev(s1)**2 + (len(s2)-1)\n",
    "                  * stdev(s2)**2)/(len(s1)+len(s2)-2))\n",
    "        cohens_d = (mean(s1) - mean(s2)) / s\n",
    "\n",
    "        if abs(cohens_d) < 0.01:\n",
    "            effsizestr = \"Vernachlässigbarer\"\n",
    "        elif abs(cohens_d) < 0.2:\n",
    "            effsizestr = \"Sehr kleiner\"\n",
    "        elif abs(cohens_d) < 0.5:\n",
    "            effsizestr = \"Kleiner\"\n",
    "        elif abs(cohens_d) < 0.8:\n",
    "            effsizestr = \"Mittlerer\"\n",
    "        elif abs(cohens_d) < 1.2:\n",
    "            effsizestr = \"Großer\"\n",
    "        elif abs(cohens_d) < 2:\n",
    "            effsizestr = \"Sehr großer\"\n",
    "        else:\n",
    "            effsizestr = \"Riesiger\"\n",
    "\n",
    "        wrap_print(\"Effektstärke (Cohen's d): %.3f - %s Effekt\" %\n",
    "                   (cohens_d, effsizestr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786ed09c-c81f-4b35-83c6-2096dc90fa98",
   "metadata": {},
   "source": [
    "Wie man sieht sind die Werte der Algorithmen relativ Stabil, die Ergebnisse der statistischen Auswertung hängen jedoch von der Anzahl der Iterationen ab. Mit fünf Iterationen sehen wir noch keinen signifikanten Unterschied. Dies ändert sich jedoch mit größeren Stichproben durch mehr Iterationen. Auch das Konfidenzinterval ist zu Beginn noch relativ groß und schrumpft durch mehr Iterationen, da die Sicherheit der Schätzung höher wird. \n",
    "\n",
    "Dies demonstriert einen wichtigen Aspekt von statistischer Analyse: Man kann zu kleinen Stichproben nicht trauen. \n",
    "\n",
    "Man sieht ebenfalls, dass die Effektstärke irreführend sein kann. Die Analyse zeigt eine mittlere Effektstärke. Der absolute Unterschied zwischen den Modellen ist mit 2% jedoch relativ klein. Die Effektstärke ist dennoch sehr hoch, da die Standardabweichung der Ergebnisse sehr klein ist. Grundsätzlich sollte man mit Effektstärken im Fall von sehr kleinen Standardabweichungen vorsichtig umgehen und diese nicht überinterpretieren. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
