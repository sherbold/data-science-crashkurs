
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>11. Statistik &#8212; Data Science Crashkurs - Eine interaktive und praktische Einführung</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="12. Big Data Processing" href="kapitel_12.html" />
    <link rel="prev" title="10. Text Mining" href="kapitel_10.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/bookcover.jpg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Data Science Crashkurs - Eine interaktive und praktische Einführung</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="vorwort.html">
                    Vorwort
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Kapitel
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="kapitel_01.html">
   1. Big Data und Data Science
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kapitel_02.html">
   2. Der Prozess von Data-Science-Projekten
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kapitel_03.html">
   3. Allgemeines zur Datenanalyse
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kapitel_04.html">
   4. Erkunden der Daten
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kapitel_05.html">
   5. Assoziationsregeln
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kapitel_06.html">
   6. Clusteranalyse
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kapitel_07.html">
   7. Klassifikation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kapitel_08.html">
   8. Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kapitel_09.html">
   9. Zeitreihenanalyse
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kapitel_10.html">
   10. Text Mining
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   11. Statistik
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kapitel_12.html">
   12. Big Data Processing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kapitel_13.html">
   13. Weiterführende Konzepte
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Appendix
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="howto.html">
   Selbst ausführen
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="notations.html">
   Notationen
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="acronyms.html">
   Abkürzungen
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Gefällt Ihnen das Buch? Möchten Sie es in den Händen halten und weitere Open Access Bücher unterstützen? <a href="https://dpunkt.de/produkt/data-science-crashkurs/">Dann kaufen Sie die Print Edition.</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/sherbold/einfuehrung-in-data-science/main?urlpath=tree/content/chapters/kapitel_11.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>
<a href="https://github.com/sherbold/einfuehrung-in-data-science"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="bottom"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/chapters/kapitel_11.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hypothesentests">
   11.1. Hypothesentests
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#t-test">
     11.1.1.
     <span class="math notranslate nohighlight">
      \(t\)
     </span>
     -Test
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#das-signifikanzniveau">
     11.1.2. Das Signifikanzniveau
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#wichtige-hypothesentests">
     11.1.3. Wichtige Hypothesentests
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#anwendung-der-tests">
     11.1.4. Anwendung der Tests
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ubliche-fehler-bei-hypothesentests">
     11.1.5. Übliche Fehler bei Hypothesentests
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#effektstarke">
   11.2. Effektstärke
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#konfidenzintervalle">
   11.3. Konfidenzintervalle
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gute-beschreibung-von-ergebnissen">
   11.4. Gute Beschreibung von Ergebnissen
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ubung">
   11.5. Übung
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mehrfaches-training">
     11.5.1. Mehrfaches Training
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#statistischer-vergleich">
     11.5.2. Statistischer Vergleich
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mehr-vergleiche">
     11.5.3. Mehr Vergleiche
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Statistik</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hypothesentests">
   11.1. Hypothesentests
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#t-test">
     11.1.1.
     <span class="math notranslate nohighlight">
      \(t\)
     </span>
     -Test
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#das-signifikanzniveau">
     11.1.2. Das Signifikanzniveau
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#wichtige-hypothesentests">
     11.1.3. Wichtige Hypothesentests
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#anwendung-der-tests">
     11.1.4. Anwendung der Tests
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ubliche-fehler-bei-hypothesentests">
     11.1.5. Übliche Fehler bei Hypothesentests
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#effektstarke">
   11.2. Effektstärke
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#konfidenzintervalle">
   11.3. Konfidenzintervalle
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gute-beschreibung-von-ergebnissen">
   11.4. Gute Beschreibung von Ergebnissen
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ubung">
   11.5. Übung
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mehrfaches-training">
     11.5.1. Mehrfaches Training
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#statistischer-vergleich">
     11.5.2. Statistischer Vergleich
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mehr-vergleiche">
     11.5.3. Mehr Vergleiche
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="statistik">
<h1><span class="section-number">11. </span>Statistik<a class="headerlink" href="#statistik" title="Permalink to this headline">#</a></h1>
<p>Im Laufe der Kapitel haben wir bereits einige Datensätze betrachtet. Einen wichtigen Aspekt haben wir aber bisher ignoriert: die Rolle des Zufalls, um Unterschiede zu erklären. Daher wollen wir uns an dieser Stelle noch mit Methoden aus der Statistik beschäftigen, die dazu geeignet sind, Aussagen darüber zu treffen, ob wir einen echten Effekt beobachten oder lediglich zufällige Schwankungen. Um zu verstehen, warum das relevant ist, betrachten wir direkt zwei Beispiele. In <a class="reference internal" href="kapitel_04.html"><span class="doc std std-doc">Kapitel 4</span></a> haben wir zum Beispiel die Verteilung von Daten mit Histogrammen visualisiert. Hier sind die Histogramme von zwei weiteren Datensätzen:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>

<span class="c1"># generate data</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span> 
<span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.2</span> <span class="c1"># mean and standard deviation</span>
<span class="n">s1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="n">s2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mu</span><span class="o">+</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">s1</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Histogramm von zufällig generierten Daten</span><span class="se">\n</span><span class="s2">Frage: Sind diese Daten normalverteilt?&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;count&quot;</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">s1</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">s2</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Histogramm von zufällig generierten Daten</span><span class="se">\n</span><span class="s1">mean(&quot;blau&quot;): </span><span class="si">%.2f</span><span class="s1"> - mean(&quot;orange&quot;): </span><span class="si">%.2f</span><span class="se">\n</span><span class="s1">Frage: Sind die Mittelwerte verschieden?&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">s1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">s2</span><span class="p">)))</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;count&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/kapitel_11_1_0.png" src="../_images/kapitel_11_1_0.png" />
</div>
</div>
<p>Das Histogramm auf der linken Seite hat eine Glockenform, was auf eine Normalverteilung hindeutet. Wie wahrscheinlich es ist, dass es sich um eine Normalverteilung handelt, ist jedoch unklar. Auf der rechten Seite sehen wir die Histogramme von zwei Stichproben <span class="math notranslate nohighlight">\(X_1 = \{x_1^1, ..., x_{n_1}^1\}\)</span> (“blau”) und <span class="math notranslate nohighlight">\(X_2 = \{x_1^2, ..., x_{n_2}^2\}\)</span> (“orange”). Diese Stichproben sind aus der “blauen” und der “orangen” Grundgesamtheit gezogen, die auch <em>Populationen</em> genannt werden. Beide Stichproben sehen sich sehr ähnlich, auch wenn der Mittelwert der blauen Daten etwas kleiner ist als bei den orangen Daten. Ob dies ein zufälliger Effekt der Stichproben ist oder ob die blaue Population im Mittel wirklich etwas kleiner ist, kann man mit dem Histogramm nicht erkennen.</p>
<p>Statistische Methoden können uns diese Fragen (mit einer gewissen Wahrscheinlichkeit) beantworten. In diesem Kapitel befassen wir uns in einer kurzen Einführung mit der ziemlich großen Welt der Statistik. Unser Ziel ist ein Grundverständnis von Hypothesentests, Effektstärken und Konfidenzintervallen. Die Hypothesen in diesem Kapitel sind nicht mit den Hypothesen eines Klassifikationsmodells zu verwechseln (siehe <a class="reference internal" href="kapitel_08.html"><span class="doc std std-doc">Kapitel 8</span></a>).</p>
<section id="hypothesentests">
<h2><span class="section-number">11.1. </span>Hypothesentests<a class="headerlink" href="#hypothesentests" title="Permalink to this headline">#</a></h2>
<p>Hypothesentests sind das wichtigste Werkzeug der <em>häufigkeitsbasierten Statistik</em> (engl. <em>frequentist statistics</em>). Bei Hypothesentests hat man Annahmen an die Daten. Durch diese Annahmen kann man Hypothesen über die Daten formulieren. Es gibt immer zwei Hypothesen: die <em>Nullhypothese</em> und die <em>Alternativhypothese</em>.</p>
<ul class="simple">
<li><p>Nullhypothese (<span class="math notranslate nohighlight">\(H_0\)</span>): Die Annahmen des Tests sind erfüllt und können nicht mit einem vorgegebenen Signifikanzniveau verworfen werden.</p></li>
<li><p>Alternativhypothese (<span class="math notranslate nohighlight">\(H_1\)</span>): Die Annahmen des Tests sind nicht erfüllt und können mit einem vorgegebenen Signifikanzniveau verworfen werden.</p></li>
</ul>
<p>Die Formulierung dieser Hypothesen basiert auf einigen abstrakten Konzepten: Was genau ist eine “Annahme” und was heißt “mit einem vorgegebenen Signifikanzniveau verwerfen”? Im Folgenden erklären wir die Bedeutung dieser Konzepte am Beispiel des  <span class="math notranslate nohighlight">\(t\)</span>-Tests.</p>
<section id="t-test">
<h3><span class="section-number">11.1.1. </span><span class="math notranslate nohighlight">\(t\)</span>-Test<a class="headerlink" href="#t-test" title="Permalink to this headline">#</a></h3>
<p>Der <span class="math notranslate nohighlight">\(t\)</span>-Test ist der Urvater der statistischen Tests und wurde von William Gosset unter dem Pseudonym “Student” entwickelt. Die älteste Version des Tests und die Wahrscheinlichkeitsverteilung, auf dem dieser Test basiert, heißen daher auch Students <span class="math notranslate nohighlight">\(t\)</span>-Test und Students <span class="math notranslate nohighlight">\(t\)</span>-Verteilung. Wir betrachten hier eine neuere Variante des <span class="math notranslate nohighlight">\(t\)</span>-Tests, nämlich Welchs <span class="math notranslate nohighlight">\(t\)</span>-Test. Welchs <span class="math notranslate nohighlight">\(t\)</span>-Test hat folgende Hypothesen:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(H_0\)</span>: Die Mittelwerte von zwei normalverteilten Populationen <span class="math notranslate nohighlight">\(X_1\)</span> und <span class="math notranslate nohighlight">\(X_2\)</span> sind gleich.</p></li>
<li><p><span class="math notranslate nohighlight">\(H_1\)</span>: <span class="math notranslate nohighlight">\(X_1\)</span> und <span class="math notranslate nohighlight">\(X_2\)</span> sind keine normalverteilten Populationen mit dem gleichen Mittelwert.</p></li>
</ul>
<p>Anhand der Hypothesen kann man bereits den Zweck des <span class="math notranslate nohighlight">\(t\)</span>-Tests erkennen: Wir wollen bestimmen können, ob die Mittelwerte unterschiedlich sind. Zum besseren Verständnis hier ein Beispiel: Wir wollen wissen, ob das Durchschnittsalter der Einwohner von Berlin gleich dem von Hamburg ist. In beiden Städten haben wir 10.000 Einwohner zufällig ausgewählt und nach dem Alter gefragt. Die Städte sind unsere Populationen, die ausgewählten Einwohner unsere Stichproben. Derartige Fragestellungen gibt es häufig: Sind zwei Medikamente gleich wirksam oder auch ist mein Random Forest gleich gut wie mein neuronales Netz?</p>
<p>Eine wichtige Eigenschaft vom <span class="math notranslate nohighlight">\(t\)</span>-Test ist, dass die Alternativhypothese nicht aussagt, dass die Mittelwerte nicht gleich sind. Sie sagt lediglich aus, dass wenn <span class="math notranslate nohighlight">\(X_1\)</span> und <span class="math notranslate nohighlight">\(X_2\)</span> beide normalverteilt sind, die Mittelwerte unterschiedlich sind. Wenn eine von beiden Populationen nicht normalverteilt ist, weiß man nicht, ob die Nullhypothese verworfen wurde, weil die Mittelwerte unterschiedlich sind oder weil es keine Normalverteilung war. Diese wichtige Eigenschaft wird oft vergessen und ist einer der häufigsten Fehler bei der Benutzung von Hypothesentests.</p>
<p>Der <span class="math notranslate nohighlight">\(t\)</span>-Test bestimmt, ob die Nullhypothese verworfen wird, basierend auf der Überlegung, wie wahrscheinlich es ist, die Stichprobe zu beobachten, wenn die Hypothese zutrifft. Für den <span class="math notranslate nohighlight">\(t\)</span>-Test heißt das, dass man berechnet, wie wahrscheinlich es ist, die Stichproben <span class="math notranslate nohighlight">\(X_1\)</span> und <span class="math notranslate nohighlight">\(X_2\)</span> zu beobachten, wenn beide aus normalverteilten Populationen mit dem gleichen Mittelwert gezogen werden. Dies ist der gleichermaßen berühmte wie berüchtigte <em>p-value</em>. Um den p-value zu bestimmen, brauchen wir eine <em>Teststatistik</em>. Im Fall vom <span class="math notranslate nohighlight">\(t\)</span>-Test ist das Students <span class="math notranslate nohighlight">\(t\)</span>-Verteilung.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>

<span class="n">rv</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">rv</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">),</span> <span class="n">rv</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.9999</span><span class="p">),</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">rv</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> 

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Students $t$-Verteilung mit 100 Freiheitsgraden&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/kapitel_11_3_0.png" src="../_images/kapitel_11_3_0.png" />
</div>
</div>
<p>Diese Verteilung sieht auf den ersten Blick aus wie eine Normalverteilung. Die <span class="math notranslate nohighlight">\(t\)</span>-Verteilung hat jedoch eine etwas breitere Glocke als die Normalverteilung, die Fläche ist also in den Randbereichen größer. Diese Ähnlichkeit zur Normalverteilung ist kein Zufall. Die <span class="math notranslate nohighlight">\(t\)</span>-Verteilung ist definiert als die erwartete Abweichung des Mittelwerts von null bei einer Stichprobe, die aus der Standardnormalverteilung mit Mittelwert null und Standardabweichung eins gezogen wurde. Die <span class="math notranslate nohighlight">\(t\)</span>-Verteilung sagt also etwas über die Unsicherheit der Mittelwerts einer Stichprobe aus. Diese Unsicherheit können wir natürlich auch für zwei Stichproben bestimmen, was dann schon sehr ähnlich zu unserer Hypothese ist.</p>
<p>Der Unterschied ist, dass die <span class="math notranslate nohighlight">\(t\)</span>-Verteilung die Unsicherheit für einen Mittelwert von null und eine Standardabweichung von eins berechnet, wir aber mit unserer Hypothese beliebige Normalverteilungen zulassen. Daher benötigen wir die Teststatistik. Diese ist für den <span class="math notranslate nohighlight">\(t\)</span>-Test definiert als</p>
<div class="math notranslate nohighlight">
\[t = \frac{mean(X_1)-mean(X_2)}{\sqrt{\frac{sd(X_1)^2}{n_1}+\frac{sd(X_2)^2}{n_2}}}.\]</div>
<p>Diese Gleichung sieht zwar kompliziert aus, ist aber - etwas vereinfacht ausgedrückt - nichts anderes als eine Standardisierung der Stichproben, sodass sich die Differenz der Mittelwerte wie bei zwei Standardnormalverteilungen verhält. Daher können wir die <span class="math notranslate nohighlight">\(t\)</span>-Verteilung benutzen, um auszurechnen, wie wahrscheinlich es ist, dass wir diese Abweichung beobachten. Hierfür berechnet man die Fläche unter der <span class="math notranslate nohighlight">\(t\)</span>-Verteilung außerhalb von <span class="math notranslate nohighlight">\(\pm t\)</span>.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tvalue</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">xfill</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="n">tvalue</span><span class="p">,</span> <span class="n">tvalue</span><span class="p">)</span>
<span class="n">xfill_left</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">rv</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">),</span><span class="o">-</span><span class="n">tvalue</span><span class="p">)</span>
<span class="n">xfill_right</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">rv</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.9999</span><span class="p">),</span><span class="n">tvalue</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;p-value mit Students $t$-Verteilung</span><span class="se">\n</span><span class="s2">Die grüne Fläche ist der p-value&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">tvalue</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="o">-</span><span class="n">tvalue</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([</span><span class="o">-</span><span class="n">tvalue</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">tvalue</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;-t&#39;</span><span class="p">,</span><span class="s1">&#39;0&#39;</span><span class="p">,</span><span class="s1">&#39;t&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">xfill</span><span class="p">,</span> <span class="n">rv</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">xfill</span><span class="p">),</span> <span class="n">y2</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">xfill_left</span><span class="p">,</span> <span class="n">rv</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">xfill_left</span><span class="p">),</span> <span class="n">y2</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">xfill_right</span><span class="p">,</span> <span class="n">rv</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">xfill_right</span><span class="p">),</span> <span class="n">y2</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/kapitel_11_5_0.png" src="../_images/kapitel_11_5_0.png" />
</div>
</div>
<p>Die grüne Fläche ist die Wahrscheinlichkeit, dass die Stichprobe einer Standardnormalverteilung um mindestens <span class="math notranslate nohighlight">\(t\)</span> von null abweicht. Da wir <span class="math notranslate nohighlight">\(t\)</span> so berechnen, dass es genau die Abweichung der Mittelwerte voneinander darstellt, entspricht dies der Wahrscheinlichkeit, dass die zwei Stichproben gezogen wurden, wenn die Populationen normalverteilt sind und den gleichen Mittelwert haben. Das ist der p-value des <span class="math notranslate nohighlight">\(t\)</span>-Tests: Die Wahrscheinlichkeit, dass die Daten beobachtet werden, wenn unsere Nullhypothese zutrifft.</p>
</section>
<section id="das-signifikanzniveau">
<h3><span class="section-number">11.1.2. </span>Das Signifikanzniveau<a class="headerlink" href="#das-signifikanzniveau" title="Permalink to this headline">#</a></h3>
<p>Der p-value gibt also an, wie wahrscheinlich es ist, die Daten zu sehen. Es ist also nur logisch, dass ein kleiner p-value darauf hindeutet, dass die Nullhypothese nicht zutrifft und verworfen werden sollte. Diese Folgerung wird durch das <em>Signifikanzniveau</em> <span class="math notranslate nohighlight">\(\alpha\)</span> formalisiert, um die <em>statistische Signifikanz</em> des Testergebnisses zu definieren. Das Signifikanzniveau ist definiert als die Wahrscheinlichkeit, dass die Nullhypothese verworfen wird, obwohl sie zutrifft. Häufig wird ein Signifikanzniveau von 0,05 oder in letzter Zeit auch 0,005 verwendet. Mit dem Signifikanzniveau können wir anhand von p-value entscheiden, ob wir die Nullhypothese verwerfen:</p>
<ul class="simple">
<li><p>Wenn <span class="math notranslate nohighlight">\(\text{p-value} &gt; \alpha\)</span> ist, können wir die Nullhypothese nicht verwerfen. Das heißt, dass die Stichproben nicht unwahrscheinlich sind, wenn die Nullhypothese wahr ist.</p></li>
<li><p>Wenn <span class="math notranslate nohighlight">\(\text{p-value} \leq \alpha\)</span> ist, verwerfen wir die Nullhypothese und haben ein statistisch signifikantes Ergebnis. Die Stichproben sind also sehr unwahrscheinlich, wenn die Nullhypothese wahr ist.</p></li>
</ul>
<p>Mit Hypothesentests erhält man keine absolute Sicherheit, die Ergebnisse stimmen nur mit einer durch das Signifikanzniveau festgelegten Wahrscheinlichkeit. Das heißt auch, dass wenn wir die Nullhypothese verwerfen, sie trotzdem wahr sein könnte. Es ist nur unwahrscheinlich - aber nicht unmöglich! -, dass diese Daten vorkommen. Deshalb verwenden wir auch die etwas komplizierten Formulierungen nicht verwerfen können bzw. verwerfen bezogen auf ein Signifikanzniveau.</p>
</section>
<section id="wichtige-hypothesentests">
<h3><span class="section-number">11.1.3. </span>Wichtige Hypothesentests<a class="headerlink" href="#wichtige-hypothesentests" title="Permalink to this headline">#</a></h3>
<p>Was wir oben im Detail für den <span class="math notranslate nohighlight">\(t\)</span>-Test erklärt haben, gilt für alle statistischen Tests: Es gibt eine Nullhypothese, in der wir Annahmen treffen. Dann berechnen wir den p-value, also die Wahrscheinlichkeit der Daten, entsprechend den Annahmen. Basierend auf dem p-value können wir bestimmen, ob wir die Nullhypothese mit einem gewissen Signifikanzniveau verwerfen. Es gibt sehr viele derartige statistische Tests. Hier sind die Nullhypothesen einiger sehr wichtiger Tests:</p>
<ul class="simple">
<li><p>Welchs <span class="math notranslate nohighlight">\(t\)</span>-Test: Die Mittelwerte zweier unabhängiger normalverteilter Populationen sind gleich.</p></li>
<li><p>Mann-Whitney-U-Test / Wilcoxon-Ranksum-Test: Die Werte einer Population dominieren die Werte einer anderen Population nicht (entspricht in etwa der Frage, ob die Mediane gleich sind).</p></li>
<li><p>Shapiro-Wilk-Test: Die Population einer Stichprobe mit einer Größe zwischen 3 und 5.000 ist normalverteilt.</p></li>
<li><p>Levene-Test: Die Varianz von einer Gruppe von Populationen ist gleich.</p></li>
<li><p>ANOVA (F-Test): Die Mittelwerte einer Gruppe von normalverteilten Populationen mit gleichen Varianzen sind gleich.</p></li>
<li><p>Kolmogorow-Smirnow-Test: Zwei Populationen haben die gleiche Wahrscheinlichkeitsverteilung.</p></li>
</ul>
<p>Wir wissen bereits, dass wir Welchs <span class="math notranslate nohighlight">\(t\)</span>-Test benutzen können, um die Mittelwerte von Normalverteilungen zu vergleichen. Wenn die Daten nicht normalverteilt sind, können wir stattdessen den Mann-Whitney-U-Test nutzen. Mithilfe des Shapiro-Wilk-Tests können wir bestimmen, ob eine Stichprobe normalverteilt ist. Wenn man mehr als zwei Datensätze vergleichen möchte, spricht man von einer Gruppe von Populationen. Mit ANOVA kann man bestimmen, ob die Mittelwerte aller dieser Populationen gleich sind, sofern es sich um Normalverteilungen mit der gleichen Varianz handelt. Die Normalverteilung können wir mit dem Shapiro-Wilk-Test überprüfen, für die Varianzen können wir den Levene-Test verwenden.</p>
<p>Ähnlich wie bei den deskriptiven Statistiken (siehe <a class="reference internal" href="kapitel_04.html"><span class="doc std std-doc">Kapitel 4</span></a>) gibt es <em>parametrische</em> und <em>nicht parametrische</em> statistische Tests. Die parametrischen Tests haben Annahmen an die Daten (z.B. Normalverteilung), die nicht parametrischen Tests machen keine derartigen Annahmen. Welchs <span class="math notranslate nohighlight">\(t\)</span>-Test ist zum Beispiel parametrisch und der Mann-Whitney-U-Test ist das nicht parametrische Gegenstück.</p>
<p>Der Kolmogorow-Smirnow-Test ist ein sehr generischer statistischer Test, da er beliebige Populationen mit kontinuierlichen Verteilungen miteinander vergleichen kann. Es gibt also nur wenige Einschränkungen, wann man den Test benutzen kann. Dennoch sollte man ihn als “letztes Mittel” betrachten, mit dem man zumindest sagen kann, ob es irgendwelche Unterschiede gibt. Was genau unterschiedlich ist, zum Beispiel die Lage, die Variabilität oder die Art der Verteilung, ist unklar. Als Vergleich: Wenn man mit dem Shapiro-Wilk-Test bestimmt, dass die Populationen normalverteilt sind, und mit Welchs <span class="math notranslate nohighlight">\(t\)</span>-Test einen signifikanten Unterschied der Mittelwerte feststellt, weiß man sehr genau, wie sich die Populationen voneinander unterscheiden.</p>
</section>
<section id="anwendung-der-tests">
<h3><span class="section-number">11.1.4. </span>Anwendung der Tests<a class="headerlink" href="#anwendung-der-tests" title="Permalink to this headline">#</a></h3>
<p>Mit dem uns jetzt bekannten Wissen über die statistischen Tests können wir die Fragen vom Anfang des Kapitels beantworten: Sind die Mittelwerte der blauen und der orangen Population unterschiedlich? Mithilfe der Hypothesentests können wir hierzu eine Aussage treffen, die mit hoher Wahrscheinlichkeit richtig ist. Hierzu müssen wir ein Signifikanzniveau <span class="math notranslate nohighlight">\(\alpha\)</span> festlegen. Anschließend können wir den Shapiro-Wilk-Test auf beide Stichproben anwenden, um zu bestimmen, ob die Populationen normalverteilt sind. Wenn dies der Fall ist, können wir die Mittelwerte mit Welchs <span class="math notranslate nohighlight">\(t\)</span>-Test vergleichen, ansonsten nehmen wir den Mann-Whitney-U-Test.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">textwrap</span> <span class="kn">import</span> <span class="n">TextWrapper</span>

<span class="n">wrapper</span> <span class="o">=</span> <span class="n">TextWrapper</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="mi">65</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">wrap_print</span><span class="p">(</span><span class="n">string</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">wrapper</span><span class="o">.</span><span class="n">wrap</span><span class="p">(</span><span class="n">string</span><span class="p">)))</span>


<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="n">pval_shapiro1</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">shapiro</span><span class="p">(</span><span class="n">s1</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">pval_shapiro2</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">shapiro</span><span class="p">(</span><span class="n">s2</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>

<span class="n">wrap_print</span><span class="p">(</span><span class="s1">&#39;p-value des Shapiro-Wilk-Tests für die &quot;blauen&quot; Daten: </span><span class="si">%.4f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">pval_shapiro1</span><span class="p">)</span>
<span class="k">if</span> <span class="n">pval_shapiro1</span><span class="o">&gt;</span><span class="n">alpha</span><span class="p">:</span>
    <span class="n">wrap_print</span><span class="p">(</span><span class="s1">&#39;Der Test hat ermittelt, dass die Daten wahrscheinlich normalverteilt sind, und wir können die Nullhypothese  nicht mit einem Signifikanzniveau von alpha=</span><span class="si">%.3f</span><span class="s1"> verwerfen.&#39;</span> <span class="o">%</span> <span class="n">alpha</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">wrap_print</span><span class="p">(</span><span class="s1">&#39;Der Test hat ermittelt, dass die Daten wahrscheinlich nicht normalverteilt sind, und wir verwerfen die Nullhypothese mit einem Signifikanzniveau von alpha=</span><span class="si">%.3f</span><span class="s1">.&#39;</span> <span class="o">%</span> <span class="n">alpha</span><span class="p">)</span>

<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;p-value des Shapiro-Wilk-Tests für die &quot;orangen&quot; Daten: </span><span class="si">%.4f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">pval_shapiro2</span><span class="p">)</span>
<span class="k">if</span> <span class="n">pval_shapiro1</span><span class="o">&gt;</span><span class="n">alpha</span><span class="p">:</span>
    <span class="n">wrap_print</span><span class="p">(</span><span class="s1">&#39;Der Test hat ermittelt, dass die Daten wahrscheinlich normalverteilt sind, und wir können die Nullhypothese nicht mit einem Signifikanzniveau von alpha=</span><span class="si">%.3f</span><span class="s1"> verwerfen.&#39;</span> <span class="o">%</span> <span class="n">alpha</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">wrap_print</span><span class="p">(</span><span class="s1">&#39;Der Test hat ermittelt, dass die Daten wahrscheinlich nicht normalverteilt sind, und wir verwerfen die Nullhypothese mit einem Signifikanzniveau von alpha=</span><span class="si">%.3f</span><span class="s1">.&#39;</span> <span class="o">%</span> <span class="n">alpha</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="k">if</span> <span class="n">pval_shapiro1</span><span class="o">&gt;</span><span class="n">alpha</span> <span class="ow">and</span> <span class="n">pval_shapiro2</span><span class="o">&gt;</span><span class="n">alpha</span><span class="p">:</span>
    <span class="n">wrap_print</span><span class="p">(</span><span class="s2">&quot;Beide Populationen sind normalverteilt. Wir benutzen Welch&#39;s t-Test.&quot;</span><span class="p">)</span>
    <span class="n">pval_equal</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">ttest_ind</span><span class="p">(</span><span class="n">s1</span><span class="p">,</span><span class="n">s2</span><span class="p">,</span><span class="n">equal_var</span><span class="o">=</span><span class="kc">False</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">()</span>    
    <span class="n">wrap_print</span><span class="p">(</span><span class="s2">&quot;p-value von Welchs t-Test: </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">pval_equal</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">pval_equal</span><span class="o">&gt;</span><span class="n">alpha</span><span class="p">:</span>
        <span class="n">wrap_print</span><span class="p">(</span><span class="s1">&#39;Der Test hat ermittelt, dass die Mittelwerte wahrscheinlich gleich sind, und wir können die Nullhypothese nicht mit einem Signifikanzniveau von alpha=</span><span class="si">%.3f</span><span class="s1"> verwerfen.&#39;</span> <span class="o">%</span> <span class="n">alpha</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">wrap_print</span><span class="p">(</span><span class="s1">&#39;Der Test hat ermittelt, dass die Mittelwerte wahrscheinlich nicht gleich sind, und wir verwerfen die Nullhypothese mit einem Signifikanzniveau von alpha=</span><span class="si">%.3f</span><span class="s1">.&#39;</span> <span class="o">%</span> <span class="n">alpha</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">wrap_print</span><span class="p">(</span><span class="s2">&quot;Mindestens eine Population ist nicht normalverteilt. Wir benutzen den Mann-Whitney-U-Test.&quot;</span><span class="p">)</span>
    <span class="n">pval_equal</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">mannwhitneyu</span><span class="p">(</span><span class="n">s1</span><span class="p">,</span><span class="n">s2</span><span class="p">,</span><span class="n">alternative</span><span class="o">=</span><span class="s1">&#39;two-sided&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">wrap_print</span><span class="p">(</span><span class="s2">&quot;p-value des Mann-Whitney-U Tests: </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">pval_equal</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">pval_equal</span><span class="o">&gt;</span><span class="n">alpha</span><span class="p">:</span>
        <span class="n">wrap_print</span><span class="p">(</span><span class="s1">&#39;Der Test hat ermittelt, dass die Populationen sich nicht dominieren, und wir können die Nullhypothese nicht mit einem Signifikanzniveau von alpha=</span><span class="si">%.3f</span><span class="s1"> verwerfen.&#39;</span> <span class="o">%</span> <span class="n">alpha</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">wrap_print</span><span class="p">(</span><span class="s1">&#39;Der Test hat ermittelt, dass eine Population die andere dominiert, und wir verwerfen die Nullhypothese mit einem Signifikanzniveau von alpha=</span><span class="si">%.3f</span><span class="s1">.&#39;</span> <span class="o">%</span> <span class="n">alpha</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>p-value des Shapiro-Wilk-Tests für die &quot;blauen&quot; Daten: 0.8290
Der Test hat ermittelt, dass die Daten wahrscheinlich
normalverteilt sind, und wir können die Nullhypothese  nicht mit
einem Signifikanzniveau von alpha=0.050 verwerfen.

p-value des Shapiro-Wilk-Tests für die &quot;orangen&quot; Daten: 0.2498
Der Test hat ermittelt, dass die Daten wahrscheinlich
normalverteilt sind, und wir können die Nullhypothese nicht mit
einem Signifikanzniveau von alpha=0.050 verwerfen.

Beide Populationen sind normalverteilt. Wir benutzen Welch&#39;s
t-Test.

p-value von Welchs t-Test: 0.000102
Der Test hat ermittelt, dass die Mittelwerte wahrscheinlich nicht
gleich sind, und wir verwerfen die Nullhypothese mit einem
Signifikanzniveau von alpha=0.050.
</pre></div>
</div>
</div>
</div>
<p>Die Tests haben also festgestellt, dass die Daten wahrscheinlich normalverteilt sind, aber die Mittelwerte nicht gleich sind. Wir haben also einen statistisch signifikanten Unterschied zwischen den blauen und den orangen Daten mit einem Signifikanzniveau von <span class="math notranslate nohighlight">\(\alpha=0.05\)</span>.</p>
</section>
<section id="ubliche-fehler-bei-hypothesentests">
<h3><span class="section-number">11.1.5. </span>Übliche Fehler bei Hypothesentests<a class="headerlink" href="#ubliche-fehler-bei-hypothesentests" title="Permalink to this headline">#</a></h3>
<p>Bei Hypothesentests steckt der Teufel im Detail, da es viele Aspekte gibt, die man vergessen oder ungenau darstellen kann, was dazu führen kann, dass man die Ergebnisse überinterpretiert. Daher wollen wir hier einige größere und häufig vorkommende Fehler nennen, damit wir diese vermeiden können.</p>
<p>Das größte Problem ist, dass man Hypothesentests nutzt, um binäre Aussagen zu machen, zum Beispiel “die Daten sind normalverteilt” statt “der statistische Test indiziert, dass die Daten mit hoher Wahrscheinlichkeit normalverteilt sind”. Der große Unterschied: Die korrekte Aussage beinhaltet, dass es eine gewisse Unsicherheit über das Ergebnis gibt, was bei der absoluten Aussage nicht der Fall ist. Dass derartige Fehler (häufig!) passieren, ist verständlich. Das korrekte Formulieren von statistischen Ergebnissen ist schwierig und die Sätze klingen oft umständlich, was dazu verleitet, lieber eine deutlich einfachere absolute Formulierung zu benutzen.</p>
<p>Ein weiteres Problem ist, dass p-values häufig falsch benutzt werden. Dies liegt daran, dass die Definition von p-value als die Wahrscheinlichkeit, die Daten unter den gegebenen Annahmen zu beobachten, relativ komplex ist. Aus diesem Grund gibt es auch viele Forscher, die am liebsten Hypothesentests komplett abschaffen und durch andere Verfahren (<em>Bayesian Statistics</em>) ersetzen würden. Es gibt aber auch sehr viele Forscher, die das Problem in der falschen Verwendung der p-values sehen, sodass lediglich eine bessere Statistikausbildung erforderlich ist. In diesem Sinne betrachten wir hier auch die zwei größten Probleme der p-values: <em>Scoring</em> und <em>p-Hacking</em>.</p>
<p>Scoring bedeutet, dass der p-value als Punktzahl interpretiert wird und dann die Unterschiede der Populationen anhand ihrer p-values sortiert werden. Dies macht jedoch keinen Sinn, da die p-values eben nicht die Wahrscheinlichkeit, dass eine Hypothese korrekt ist, schätzen, sondern nur, dass die Daten zur Annahme passen. Eine Sortierung wäre also stattdessen eine Art Bewertung der Daten, was nicht gewollt ist.</p>
<p>Das p-Hacking passiert oft unbewusst. Auch hier liegt das Problem daran, dass die p-values die Wahrscheinlichkeit sind, dass die Daten unter Berücksichtigung der Annahmen generiert werden. Ein p-value von 0,05 bedeutet also, dass es eine 5%ige Wahrscheinlichkeit gibt, dass diese Daten generiert werden, unter der Annahme, dass die Nullhypothese zutrifft. Mit anderen Worten, es wird vom Test sogar erwartet, dass es eine gewisse Anzahl von <em>falsch-positiven Testergebnissen</em> gibt, also dass wir die Nullhypothese verwerfen, obwohl diese zutrifft. Dies ist im Allgemeinen kein Problem, solange die Wahrscheinlichkeit hierfür niedrig ist. Wenn man jedoch 20 Tests durchführt und jeder Test mit 5% Wahrscheinlichkeit falsch-positiv ist, ist es fast sicher, dass es falsch-positive Ergebnisse gibt. Diesem Effekt kann man entgegenwirken, indem man ein höheres Signifikanzniveau verlangt, was bedeutet, dass der p-value zum Verwerfen der Hypothesen kleiner sein muss, wodurch man die Wahrscheinlichkeit von falsch-positiven Ergebnissen reduziert. Man spricht hierbei auch vom <em>p-value adjustment</em>, zum Beispiel durch die <em>Bonferonni-Korrektur</em> <a class="footnote-reference brackets" href="#bonferroni" id="id1">1</a>. Derartiges p-Hacking ist oft keine Absicht, sondern geschieht durch die Analyse von Teilgruppen. Um zu unserem Beispiel vom Alter der Einwohner zurückzukommen: Auch wenn Berlin und Hamburg das gleiche Durchschnittsalter hätten, würde man sehr sicher Stadtteile finden, wo die Abweichung größer wäre und der Unterschied dadurch signifikant. Ein berühmtes Beispiel dafür ist dieser medizinische Fachartikel <a class="footnote-reference brackets" href="#phacking" id="id2">2</a>: Die Autoren wurden von den Herausgebern gezwungen, Teilgruppen zu analysieren. Um zu demonstrieren, dass dies zu falsch-positiven Ergebnissen führt, haben sie auch eine Analyse der Auswirkungen der Sternzeichen auf die Behandlung mit aufgenommen.</p>
</section>
</section>
<section id="effektstarke">
<h2><span class="section-number">11.2. </span>Effektstärke<a class="headerlink" href="#effektstarke" title="Permalink to this headline">#</a></h2>
<p>Die Signifikanz von Ergebnissen bedeutet nicht immer, dass ein Unterschied auch eine Bedeutung hat. Für unsere blauen und orangen Daten haben wir folgende Mittelwerte und Standardabweichungen:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;mean(&quot;blue&quot;)   = </span><span class="si">%.2f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">s1</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;sd(&quot;blue&quot;)     = </span><span class="si">%.2f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">s1</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;mean(&quot;orange&quot;) = </span><span class="si">%.2f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">s2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;sd(&quot;orange&quot;)   = </span><span class="si">%.2f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">s2</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>mean(&quot;blue&quot;)   = -0.01
sd(&quot;blue&quot;)     = 0.19
mean(&quot;orange&quot;) = 0.07
sd(&quot;orange&quot;)   = 0.20
</pre></div>
</div>
</div>
</div>
<p>Der Unterschied der Mittelwerte ist im Verhältnis zu Standardabweichung also sehr klein. Die <em>Effektstärke</em> erweitert das Konzept der Signifikanz mit einem Maß dafür, wie groß die Differenz ist. Für normalverteilte Daten kann die Effektstärke für den Unterschied der Mittelwerte durch Cohens <span class="math notranslate nohighlight">\(d\)</span> berechnet werden, was definiert ist als</p>
<p>Der Unterschied der Mittelwerte ist im Verhältnis zu Standardabweichung also sehr klein. Die <em>Effektstärke</em> erweitert das Konzept der Signifikanz mit einem Maß dafür, wie groß die Differenz ist. Für normalverteilte Daten kann die Effektstärke vom Unterschied der Mittelwerte durch Cohen’s <span class="math notranslate nohighlight">\(d\)</span> berechnet werden, was definiert ist als</p>
<div class="math notranslate nohighlight">
\[d = \frac{mean(X_1)-mean(X_2)}{s}\]</div>
<p>mit</p>
<div class="math notranslate nohighlight">
\[s = \sqrt{\frac{(n_1-1)\cdot sd(X_1)^2+(n_2-1)\cdot sd(X_2)^2}{n_1+n_2-2}}.\]</div>
<p>Der Wert <span class="math notranslate nohighlight">\(s\)</span> definiert die <em>gepoolte Standardabweichung</em> zweier Stichproben, definiert als das nach der Anzahl der Datenpunkte gewichtete Mittel der Standardabweichungen der Stichproben. Daher ist Cohens <span class="math notranslate nohighlight">\(d\)</span> nichts anderes als das Verhältnis der Mittelwertdifferenz zur Standardabweichung und <span class="math notranslate nohighlight">\(d=1\)</span> bedeutet, dass die Mittelwerte eine Standardabweichung voneinander entfernt liegen. Basierend auf Cohen und Sawilowski kann man <a class="reference internal" href="#tbl-effects"><span class="std std-numref">Table 11.1</span></a> zur Interpretation der Größenordnung der Effektstärke benutzen <a class="footnote-reference brackets" href="#sawilowski" id="id3">3</a>.</p>
<table class="colwidths-auto table" id="tbl-effects">
<caption><span class="caption-number">Table 11.1 </span><span class="caption-text">Effektstärken von Cohens <span class="math notranslate nohighlight">\(d\)</span></span><a class="headerlink" href="#tbl-effects" title="Permalink to this table">#</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>Cohens <span class="math notranslate nohighlight">\(d\)</span></p></th>
<th class="head"><p>Effektstärke</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(\vert d \vert &lt; 0.01\)</span></p></td>
<td><p>Vernachlässigbar /  Negligible</p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(\vert d \vert \geq 0.01\)</span></p></td>
<td><p>Sehr klein / Very small</p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(\vert d \vert \geq 0.2\)</span></p></td>
<td><p>Klein / Small</p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(\vert d \vert \geq 0.5\)</span></p></td>
<td><p>Mittel / Medium</p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(\vert d \vert \geq 0.8\)</span></p></td>
<td><p>Groß / Large</p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(\vert d \vert \geq 1.2\)</span></p></td>
<td><p>Sehr groß / Very large</p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(\vert d \vert \geq 2.0\)</span></p></td>
<td><p>Riesig / Huge</p></td>
</tr>
</tbody>
</table>
<p>Diese Tabelle wurde zwar für die Sozialwissenschaften erstellt, wird aber dennoch sehr häufig auch in anderen Domänen verwendet. In unserem Beispiel haben wir folgende Effektstärke:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">statistics</span> <span class="kn">import</span> <span class="n">mean</span><span class="p">,</span> <span class="n">stdev</span>
<span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">sqrt</span>

<span class="n">s</span> <span class="o">=</span> <span class="n">sqrt</span><span class="p">(</span> <span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">s1</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">stdev</span><span class="p">(</span><span class="n">s1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">s2</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">stdev</span><span class="p">(</span><span class="n">s2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">s1</span><span class="p">)</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">s2</span><span class="p">)</span><span class="o">-</span><span class="mi">2</span><span class="p">))</span>
<span class="n">cohens_d</span> <span class="o">=</span> <span class="p">(</span><span class="n">mean</span><span class="p">(</span><span class="n">s1</span><span class="p">)</span> <span class="o">-</span> <span class="n">mean</span><span class="p">(</span><span class="n">s2</span><span class="p">))</span> <span class="o">/</span> <span class="n">s</span>

<span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">cohens_d</span><span class="p">)</span><span class="o">&lt;</span><span class="mf">0.01</span><span class="p">:</span>
    <span class="n">effsizestr</span> <span class="o">=</span> <span class="s2">&quot;vernachlässigbar&quot;</span>
<span class="k">elif</span> <span class="nb">abs</span><span class="p">(</span><span class="n">cohens_d</span><span class="p">)</span><span class="o">&lt;</span><span class="mf">0.2</span><span class="p">:</span>
    <span class="n">effsizestr</span> <span class="o">=</span> <span class="s2">&quot;sehr kleiner&quot;</span>
<span class="k">elif</span> <span class="nb">abs</span><span class="p">(</span><span class="n">cohens_d</span><span class="p">)</span><span class="o">&lt;</span><span class="mf">0.5</span><span class="p">:</span>
    <span class="n">effsizestr</span> <span class="o">=</span> <span class="s2">&quot;kleiner&quot;</span>
<span class="k">elif</span> <span class="nb">abs</span><span class="p">(</span><span class="n">cohens_d</span><span class="p">)</span><span class="o">&lt;</span><span class="mf">0.8</span><span class="p">:</span>
    <span class="n">effsizestr</span> <span class="o">=</span> <span class="s2">&quot;mittelerer&quot;</span>
<span class="k">elif</span> <span class="nb">abs</span><span class="p">(</span><span class="n">cohens_d</span><span class="p">)</span><span class="o">&lt;</span><span class="mf">1.2</span><span class="p">:</span>
    <span class="n">effsizestr</span> <span class="o">=</span> <span class="s2">&quot;großer&quot;</span>
<span class="k">elif</span> <span class="nb">abs</span><span class="p">(</span><span class="n">cohens_d</span><span class="p">)</span><span class="o">&lt;</span><span class="mi">2</span><span class="p">:</span>
    <span class="n">effsizestr</span> <span class="o">=</span> <span class="s2">&quot;sehr großer&quot;</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">effsizestr</span> <span class="o">=</span> <span class="s2">&quot;riesiger&quot;</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Effektstärke (Cohens d): </span><span class="si">%.3f</span><span class="s2"> - </span><span class="si">%s</span><span class="s2"> Effekt&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">cohens_d</span><span class="p">,</span> <span class="n">effsizestr</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Effektstärke (Cohens d): -0.393 - kleiner Effekt
</pre></div>
</div>
</div>
</div>
<p>Es gibt also einen kleinen Effekt. Das passt auch zu dem, was wir im Histogramm sehen: Es gibt zwar einen Unterschied zwischen den Stichproben, der ist aber klein, wie wir jetzt mithilfe von Cohens <span class="math notranslate nohighlight">\(d\)</span> bestätigt haben.</p>
</section>
<section id="konfidenzintervalle">
<h2><span class="section-number">11.3. </span>Konfidenzintervalle<a class="headerlink" href="#konfidenzintervalle" title="Permalink to this headline">#</a></h2>
<p>Wenn man den Mittelwert anhand einer Stichprobe schätzt, ist es naheliegend, zu fragen, wie gut diese Schätzung ist. Das hängt von zwei Faktoren ab: der Größe der Stichprobe und der Variabilität der Daten. Dies erkennt man schnell an einem Beispiel: Angenommen wir wollen das Durchschnittsalter unserer Kunden bestimmen. Dass die Schätzung besser wird, je mehr Kunden wir befragen, ist offensichtlich. Wenn die ersten Kunden alle mit Zahlen zwischen 18 und 25 antworten, haben wir eine kleine Variabilität der Antworten und können den Wert schon gut eingrenzen. Wenn die ersten Kunden jedoch Zahlen zwischen 18 und 86 nennen, haben wir eine größere Unsicherheit und müssen mehr Kunden befragen, um zu einem guten Schätzwert zu kommen.</p>
<p>Dies ist auch für die Bewertung von Klassifikationsmodellen relevant. Angenommen wir haben ein Klassifikationsmodell für die Abwanderung von Kunden, das auf den Daten von fünf Filialen trainiert wird und mit 15 Filialen ausgewertet wird. Es gibt dann 15 Schätzwerte für die Güte dieses Modells. Als fiktive Ergebnisse nehmen wir an, dass die Accuracy normalverteilt mit einem Mittelwert von 0,83 und einer Standardabweichung von 0,13 ist. Für die weitere Anwendung ist folgende Frage sehr wichtig: Welchen Mittelwert erwarten wir, wenn wir das Modell bei 15 weiteren Filialen anwenden?</p>
<p>Dies kann man mithilfe von <em>Konfidenzintervallen</em> berechnen. Ein <span class="math notranslate nohighlight">\(C\%\)</span>-Konfidenzintervall <span class="math notranslate nohighlight">\(\theta\)</span> für einen Parameter <span class="math notranslate nohighlight">\(p\)</span> ist ein Intervall, in dem <span class="math notranslate nohighlight">\(p\)</span> mit <span class="math notranslate nohighlight">\(C\%\)</span> Wahrscheinlichkeit liegt. Konfidenzintervalle kann man für beliebige statistische Merkmale <span class="math notranslate nohighlight">\(p\)</span> berechnen, auch wenn sie meistens für den Mittelwert berechnet werden. Der wahre Wert von <span class="math notranslate nohighlight">\(p\)</span> liegt dann mit hoher Wahrscheinlichkeit, nämlich mit <span class="math notranslate nohighlight">\(C\%\)</span>, in diesem Intervall. Die Wahrscheinlichkeit <span class="math notranslate nohighlight">\(C\)</span> nennt man das Konfidenzniveau. Für ein Konfidenzniveau von <span class="math notranslate nohighlight">\(C=0,95\)</span> haben wir also eine 95%-Chance, dass der Mittelwert von weiteren Stichproben im Konfidenzintervall liegt.</p>
<p>Für die Stichprobe <span class="math notranslate nohighlight">\(X = \{x_1, ..., x_n\}\)</span> einer normalverteilten Population kann man das Konfidenzintervall für den Mittelwert berechnen als</p>
<div class="math notranslate nohighlight">
\[\theta = [mean(X) - z_C\frac{sd(X)}{\sqrt{n}},  mean(X) + z_C\frac{sd(X)}{\sqrt{n}}], \]</div>
<p>wobei <span class="math notranslate nohighlight">\(z_C\)</span> der sogenannte <em>z-value</em> des Konfidenzniveaus ist. Die Formel passt zur Intuition: Das Konfidenzintervall wird kleiner, wenn die Stichprobe größer oder die Standardabweichung kleiner ist. In der Praxis liest man den Wert <span class="math notranslate nohighlight">\(z_C\)</span> einfach aus einer Tabelle ab, zum Beispiel direkt aus <a class="reference internal" href="#tbl-zvalues"><span class="std std-numref">Table 11.2</span></a>.</p>
<table class="colwidths-auto table" id="tbl-zvalues">
<caption><span class="caption-number">Table 11.2 </span><span class="caption-text">z-values für häufig verwendete Konfidenzniveaus</span><a class="headerlink" href="#tbl-zvalues" title="Permalink to this table">#</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p><span class="math notranslate nohighlight">\(C\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(z_C\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>90%</p></td>
<td><p>1,645</p></td>
</tr>
<tr class="row-odd"><td><p>95%</p></td>
<td><p>1,96</p></td>
</tr>
<tr class="row-even"><td><p>99%</p></td>
<td><p>2,58</p></td>
</tr>
<tr class="row-odd"><td><p>99,5%</p></td>
<td><p>2,807</p></td>
</tr>
<tr class="row-even"><td><p>99,9%</p></td>
<td><p>3,291</p></td>
</tr>
</tbody>
</table>
<p>In dieser Tabelle stehen die z-values der Standardnormalverteilung. Der z-value ist so gewählt, dass die Fläche unter der Dichtefunktion der Normalverteilung <span class="math notranslate nohighlight">\(C\)</span> entspricht.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">sqrt</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">norm</span>

<span class="n">mu</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">zc</span> <span class="o">=</span> <span class="mf">1.96</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">mu</span> <span class="o">-</span> <span class="mi">3</span><span class="o">*</span><span class="n">sigma</span><span class="p">,</span> <span class="n">mu</span> <span class="o">+</span> <span class="mi">3</span><span class="o">*</span><span class="n">sigma</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>
<span class="n">xfill</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="n">zc</span><span class="p">,</span> <span class="n">zc</span><span class="p">)</span>

<span class="n">fix</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Dichtefunktion der Standardnormalverteilung (mean=0, sd=1)&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">xfill</span><span class="p">,</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">xfill</span><span class="p">),</span> <span class="n">y2</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([</span><span class="o">-</span><span class="n">zc</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">zc</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([</span><span class="s1">&#39;$-z_C$&#39;</span><span class="p">,</span><span class="s1">&#39;0&#39;</span><span class="p">,</span><span class="s1">&#39;$z_C$&#39;</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="s2">&quot;C% Wahrscheinlichkeit&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/kapitel_11_13_0.png" src="../_images/kapitel_11_13_0.png" />
</div>
</div>
<p>In unserem Beispiel erhalten wir für verschiedene Konfidenzlevel die folgenden Konfidenzintervalle:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mymu</span> <span class="o">=</span> <span class="mf">0.83</span>
<span class="n">mysd</span> <span class="o">=</span> <span class="mf">0.13</span>
<span class="n">myn</span> <span class="o">=</span> <span class="mi">15</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">)</span>
<span class="n">y_upper</span> <span class="o">=</span> <span class="mf">0.83</span><span class="o">+</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="n">mysd</span><span class="o">/</span><span class="n">sqrt</span><span class="p">(</span><span class="n">myn</span><span class="p">)</span>
<span class="n">y_lower</span> <span class="o">=</span> <span class="mf">0.83</span><span class="o">-</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="n">mysd</span><span class="o">/</span><span class="n">sqrt</span><span class="p">(</span><span class="n">myn</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y_upper</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;navy&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y_lower</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;navy&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mf">0.7</span><span class="p">,</span><span class="mf">0.999</span><span class="p">],[</span><span class="mf">0.83</span><span class="p">,</span><span class="mf">0.83</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_upper</span><span class="p">,</span> <span class="n">y2</span><span class="o">=</span><span class="n">y_lower</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Konfidenzintervalle für verschiedene Konfidenzniveaus</span><span class="se">\n</span><span class="s1">mean=0.83, sd=0.13, n=15&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Konfidenzniveau&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Konfidenzintervall&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/kapitel_11_15_0.png" src="../_images/kapitel_11_15_0.png" />
</div>
</div>
<p>Ähnlich wie bei p-value wird auch das Konfidenzintervall häufig falsch interpre-tiert. Hier sind einige korrekte Interpretationen eines <span class="math notranslate nohighlight">\(C\%\)</span>-Konfidenzintervalls:</p>
<ul class="simple">
<li><p>Es gibt eine <span class="math notranslate nohighlight">\(C\%\)</span>-Chance, dass der gemessene Wert (zum Beispiel Mittelwert) bei zukünftigen Wiederholungen des gleichen Experiments in das Intervall <span class="math notranslate nohighlight">\(\theta\)</span> fällt.</p></li>
<li><p>Es gibt keinen statistisch signifikanten Unterschied zwischen dem geschätzten Wert und allen Werten in <span class="math notranslate nohighlight">\(\theta\)</span> mit einem Signifikanzniveau von <span class="math notranslate nohighlight">\(1-C\%\)</span>.</p></li>
<li><p>Es gibt eine <span class="math notranslate nohighlight">\(1-C\%\)</span>-Wahrscheinlichkeit der Stichprobe, wenn der wahre Wert außerhalb des Intervalls <span class="math notranslate nohighlight">\(\theta\)</span> liegt.</p></li>
</ul>
<p>Übliche falsche Interpretationen des Konfidenzintervalls sind zum Beispiel:</p>
<ul class="simple">
<li><p>Der wahre Wert von <span class="math notranslate nohighlight">\(p\)</span> liegt mit <span class="math notranslate nohighlight">\(C\%\)</span> Wahrscheinlichkeit in <span class="math notranslate nohighlight">\(\theta\)</span>. Ähnlich wie beim p-value bei Hypothesentests liefern Konfidenzintervalle nur eine Aussage über die Wahrscheinlichkeit bei Stichproben.</p></li>
<li><p><span class="math notranslate nohighlight">\(C\%\)</span> der beobachteten Daten liegen innerhalb von <span class="math notranslate nohighlight">\(\theta\)</span>. Hier wird das Konfidenzintervall mit den Quantilen verwechselt.</p></li>
</ul>
</section>
<section id="gute-beschreibung-von-ergebnissen">
<h2><span class="section-number">11.4. </span>Gute Beschreibung von Ergebnissen<a class="headerlink" href="#gute-beschreibung-von-ergebnissen" title="Permalink to this headline">#</a></h2>
<p>In der Wissenschaft, aber auch in der Praxis, wird häufig nur geschaut, ob es Unterschiede gibt und eventuell noch ob diese signifikant sind. Eine saubere statistische Bewertung von Projektergebnissen sollte aber darüber hinaus gehen und zum Beispiel auch die Effektstärke und die Konfidenzintervalle beinhalten. Außerdem sollte man die statistische Auswertung zu Beginn eines Projekts planen. Andernfalls riskiert man das oben beschriebene p-Hacking, indem man Experimente immer weiter anpasst, bis man ein gewünschtes Ergebnis gefunden hat. In der Wissenschaft führt dies zur Registrierung von Studien, bei denen das Protokoll bereits vor der Durchführung festgelegt wird. Dieses Vorgehen hat sich bereits bei klinischen Studien in der Medizin bewährt und vermeidet falsch-positive Ergebnisse.</p>
<p>In diesem Kapitel haben wir uns nur mit der häufigkeitsbasierten Statistik beschäftigt. Es gibt auch noch einen anderen Ansatz, die Bayesian Statistik, die im Kern auf dem Satz von Bayes (siehe <a class="reference internal" href="kapitel_07.html"><span class="doc std std-doc">Kapitel 7</span></a>) basiert. Hier wird direkt geschätzt, wie wahrscheinlich es ist, dass eine Hypothese wahr ist. Dies hat den Vorteil, dass die Ergebnisse einfacher zu interpretieren sind. Die Theorie und Anwendung ist hier jedoch etwas komplexer, weshalb die häufigkeitsbasierte Statistik weiterhin bei vielen Analysen das Mittel der Wahl ist.</p>
</section>
<section id="ubung">
<h2><span class="section-number">11.5. </span>Übung<a class="headerlink" href="#ubung" title="Permalink to this headline">#</a></h2>
<p>In dieser Übung wenden wir die eingeführten statistischen Methoden zum besseren Verständnis an. Hierzu vergleichen wir verschiedene Klassifikationsmodelle auf den Irisdaten <a class="footnote-reference brackets" href="#iris" id="id4">4</a>.</p>
<section id="mehrfaches-training">
<h3><span class="section-number">11.5.1. </span>Mehrfaches Training<a class="headerlink" href="#mehrfaches-training" title="Permalink to this headline">#</a></h3>
<p>Erstellen Sie fünf zufällige Aufteilungen der Irisdaten in je 50% Trainingsdaten und 50% Testdaten. Trainieren Sie ein 5-Nearest-Neighbor-Modell und einen Random Forest (mit 100 Random Trees) für jede dieser Aufteilungen. Berechnen Sie die Güte für jedes dieser Modelle mit MCC und erstellen Sie für jedes Modell eine Liste mit den Ergebnissen.</p>
</section>
<section id="statistischer-vergleich">
<h3><span class="section-number">11.5.2. </span>Statistischer Vergleich<a class="headerlink" href="#statistischer-vergleich" title="Permalink to this headline">#</a></h3>
<p>Vergleichen Sie das arithmetische Mittel, die Standardabweichung, den Median, das Minimum und das Maximum des MCC für beide Algorithmen. Benutzen Sie geeignete statistische Tests, um zu bestimmen, ob der Unterschied signifikant ist. Falls der Unterschied signifikant ist, berechnen Sie Cohens <span class="math notranslate nohighlight">\(d\)</span>, um die Effektstärke zu bestimmen. Berechnen Sie außerdem das 95%-Konfidenzintervall des arithmetischen Mittels von MCC.</p>
</section>
<section id="mehr-vergleiche">
<h3><span class="section-number">11.5.3. </span>Mehr Vergleiche<a class="headerlink" href="#mehr-vergleiche" title="Permalink to this headline">#</a></h3>
<p>Wiederholen Sie diese Auswertung mit 10, 50 und 100 zufälligen Aufteilungen der Irisdaten. Wie verändern sich die Ergebnisse?</p>
<hr class="footnotes docutils" />
<dl class="footnote brackets">
<dt class="label" id="bonferroni"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p><a class="reference external" href="https://mathworld.wolfram.com/BonferroniCorrection.html">https://mathworld.wolfram.com/BonferroniCorrection.html</a></p>
</dd>
<dt class="label" id="phacking"><span class="brackets"><a class="fn-backref" href="#id2">2</a></span></dt>
<dd><p><a class="reference external" href="https://doi.org/10.1016/S0140-6736%2888%2992833-4">https://doi.org/10.1016/S0140-6736(88)92833-4</a></p>
</dd>
<dt class="label" id="sawilowski"><span class="brackets"><a class="fn-backref" href="#id3">3</a></span></dt>
<dd><p><a class="reference external" href="https://doi.org/10.22237%2Fjmasm%2F1257035100">https://doi.org/10.22237/jmasm/1257035100</a></p>
</dd>
<dt class="label" id="iris"><span class="brackets"><a class="fn-backref" href="#id4">4</a></span></dt>
<dd><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html">https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html</a></p>
</dd>
</dl>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./chapters"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="kapitel_10.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">10. </span>Text Mining</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="kapitel_12.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">12. </span>Big Data Processing</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Steffen Herbold<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>