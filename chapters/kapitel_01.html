
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>1. Big Data und Data Science &#8212; ARBEITSVERSION - Data Science Crashkurs - Eine interaktive und praktische Einführung - Bitte lesen sie das Vorwort für weitere Informationen</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="2. Der Prozess von Data-Science-Projekten" href="kapitel_02.html" />
    <link rel="prev" title="WICHTIG: Arbeitsversion" href="vorwort.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">ARBEITSVERSION - Data Science Crashkurs - Eine interaktive und praktische Einführung - Bitte lesen sie das Vorwort für weitere Informationen</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="vorwort.html">
   WICHTIG: Arbeitsversion
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Kapitel
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   1. Big Data und Data Science
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kapitel_02.html">
   2. Der Prozess von Data-Science-Projekten
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kapitel_03.html">
   3. Allgemeines zur Datenanalyse
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kapitel_04.html">
   4. Erkunden der Daten
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kapitel_05.html">
   5. Assoziationsregeln
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kapitel_06.html">
   6. Clusteranalyse
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kapitel_07.html">
   7. Klassifikation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kapitel_08.html">
   8. Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kapitel_09.html">
   9. Zeitreihenanalyse
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kapitel_10.html">
   10. Text Mining
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kapitel_11.html">
   11. Statistik
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kapitel_12.html">
   12. Big Data Processing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kapitel_13.html">
   13. Weiterführende Konzepte
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Appendix
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="howto.html">
   Selbst ausführen
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="notations.html">
   Notationen
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/chapters/kapitel_01.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/sherbold/einfuehrung-in-data-science"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/sherbold/einfuehrung-in-data-science/main?urlpath=tree/content/chapters/kapitel_01.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#einfuhrung-in-big-data">
   1.1. Einführung in Big Data
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#volumen">
     1.1.1. Volumen
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#velocity-geschwindigkeit">
     1.1.2. Velocity / Geschwindigkeit
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#variety-vielfalt">
     1.1.3. Variety / Vielfalt
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#innovative-informationsverarbeitungsmethoden">
     1.1.4. Innovative Informationsverarbeitungsmethoden
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#wissen-generieren-entscheidungen-treffen-prozesse-automatisieren">
     1.1.5. Wissen generieren, Entscheidungen treffen, Prozesse automatisieren.
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#noch-mehr-vs">
     1.1.6. Noch mehr Vs
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#einfuhrung-in-data-science">
   1.2. Einführung in Data Science
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#was-gehort-zu-data-science">
     1.2.1. Was gehört zu Data Science?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#beispielanwendungen">
     1.2.2. Beispielanwendungen
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fahigkeiten-von-data-scientists">
   1.3. Fähigkeiten von Data Scientists
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="big-data-und-data-science">
<h1><span class="section-number">1. </span>Big Data und Data Science<a class="headerlink" href="#big-data-und-data-science" title="Permalink to this headline">¶</a></h1>
<p>Zuerst wollen wir uns etwas mit Begriffen beschäftigen, um zu verstehen, worum es beim Thema Data Science geht. Aufbauend auf dem Begriff Big Data wird aufgezeigt, was eigentlich alles zu Data Science gehört und welche Fähigkeiten Data Scientists benötigen.</p>
<div class="section" id="einfuhrung-in-big-data">
<h2><span class="section-number">1.1. </span>Einführung in Big Data<a class="headerlink" href="#einfuhrung-in-big-data" title="Permalink to this headline">¶</a></h2>
<p>Den Begriff <em>Big Data</em> gibt es jetzt bereits seit einigen Jahren und der ursprüngliche mit diesem Thema verbundene Hype ist längst Vergangenheit. Stattdessen gibt es neue Buzzwords, wie das <em>Internet der Dinge</em> (engl. Internet of Things), die <em>künstliche Intelligenz</em> (engl. <em>Artificial Intelligence</em>), und hierbei insbesondere auch die <em>tiefen neuronalen Netze</em> (engl. <em>Deep Neural Network</em>, <em>Deep Learning</em>). Nichtsdestotrotz ist Big Data mit diesen neuen Themen eng verbunden und häufig eine Voraussetzung oder zumindest eine verwandte Technologie.</p>
<p>Trotz der anhaltenden Relevanz des Themas ist dennoch häufig kein gutes Verständnis für den Unterschied zwischen vielen Daten und Big Data vorhanden. Ein gutes Verständnis der Besonderheiten und Eigenschaften von Big Data und von den damit verbundenen Implikationen und Problemen ist jedoch zwingend notwendig, wenn man auf Big Data aufbauende Technologien in Projekten einsetzen will. Der Grund für Missverständnisse rund um den Begriff Big Data ist einfach: Wir denken intuitiv an “große Datenmengen”. Eine derart vereinfachte Begriffsdefinition ignoriert jedoch wesentliche Aspekte von Big Data. Backups sind ein gutes Beispiel für große Datenmengen, die nicht Big Data sind. In modernen Rechenzentren werden Backups auf Hintergrundspeichern mit einer hohen Bitstabilität, aber auch einer hohen Latenz gespeichert. Dort lagern häufig riesige Datenmengen in der Hoffnung, dass sie nie gebraucht werden, bevor sie gelöscht oder überschrieben werden. Es gibt noch einen weiteren Grund, warum es unpraktisch ist, Big Data nur über das Datenvolumen zu definieren: Wir müssten die Definition ständig anpassen, da die Speicherkapazitäten, die Rechenkraft und der Arbeitsspeicher stetig wachsen.
Eine bessere und allgemein akzeptierte Definition für Big Data basiert auf den <em>drei Vs</em> <a class="footnote-reference brackets" href="#gartner" id="id1">1</a>.</p>
<blockquote>
<div><p><strong>Definition von Big Data:</strong></p>
<p>Als Big Data bezeichnet man Daten, die ein hohes <em>Volumen</em>, eine hohe <em>Geschwindigkeit</em> (engl. <em>velocity</em>) und eine hohe <em>Vielfalt</em> (engl. <em>variety</em>) haben, sodass man kosteneffiziente und innovative Informationsverarbeitungsmethoden benötigt, um Wissen zu generieren, Entscheidungen zu treffen oder Prozesse zu automatisieren.</p>
</div></blockquote>
<p>Zum besseren Verständnis zerlegen wir nun diese Definition in ihre Einzelteile und betrachten diese genauer. Hierbei wird klar werden, warum Big Data mehr ist als nur Datenvolumen.</p>
<div class="section" id="volumen">
<h3><span class="section-number">1.1.1. </span>Volumen<a class="headerlink" href="#volumen" title="Permalink to this headline">¶</a></h3>
<p>Auch wenn das Datenvolumen nicht der einzig wichtige Faktor ist, ist es dennoch entscheidend. Nicht umsonst heißt es Big Data. Dass keine bestimmte Datengröße das Kriterium sein kann, wird schon klar, wenn man sich überlegt, dass Google die Forschungsarbeit, in der MapReduce vorgestellt wurde, bereits 2006 publiziert hat <a class="footnote-reference brackets" href="#mapreducepaper" id="id2">2</a>. Zu diesem Zeitpunkt war ein Terabyte noch ein sehr großes Datenvolumen. Im Jahr 2021 ist dies lediglich die Festplattengröße des Laptops, auf dem dieses Buch geschrieben wurde. Ein weiteres Beispiel ist das Wachstum des Datenvolumens, das im Internet jährlich übertragen wird (<a class="reference internal" href="#fig-webtraffic"><span class="std std-numref">Fig. 1.1</span></a>).</p>
<div class="figure align-default" id="fig-webtraffic">
<a class="reference internal image-reference" href="../_images/webtraffic.png"><img alt="../_images/webtraffic.png" src="../_images/webtraffic.png" style="width: 400px;" /></a>
<p class="caption"><span class="caption-number">Fig. 1.1 </span><span class="caption-text">Wachstum des Datenvolumens im Internetverkehr</span><a class="headerlink" href="#fig-webtraffic" title="Permalink to this image">¶</a></p>
</div>
<p>Eine vereinfachte Richtlinie für das Datenvolumen lautet, dass es mehr Daten sein müssen, als in den Arbeitsspeicher moderner Server passen. Besser ist es jedoch, wenn man sich einfach die Frage stellt, ob es möglich ist, die Daten (oft) zu kopieren, insbesondere auch über Netzwerkverbindungen. Ist dies nicht mehr der Fall, handelt es sich vermutlich um genug Daten, um von Big Data zu sprechen. In extremen Fällen sind die Daten sogar so groß, dass man sie gar nicht über das Netzwerk kopieren kann. Stattdessen nutzt man das <em>Sneaker Net</em> <a class="footnote-reference brackets" href="#sneakernet" id="id3">3</a>: Die Daten werden direkt auf Festplatten verschickt. In Bezug auf den Datendurchsatz ist ein mit Festplatten beladenes Transportflugzeug unschlagbar. Die Latenz lässt jedoch zu wünschen übrig. Ein Beispiel für eine Anwendung, die ohne das Sneaker Net nicht geklappt hätte, ist die Erstellung des ersten Bilds von einem schwarzen Loch <a class="footnote-reference brackets" href="#blackhole" id="id4">4</a>.</p>
</div>
<div class="section" id="velocity-geschwindigkeit">
<h3><span class="section-number">1.1.2. </span>Velocity / Geschwindigkeit<a class="headerlink" href="#velocity-geschwindigkeit" title="Permalink to this headline">¶</a></h3>
<p>Die Velocity ist die Geschwindigkeit, mit der neue Daten generiert, verarbeitet und/oder ausgewertet werden müssen. Es gibt viele Beispiele für Daten die eine hohe Geschwindigkeit haben, zum Beispiel die durch Sensoren wie LIDAR und Kameras erfassten Daten von autonomen Fahrzeugen. Derartige Daten können in kürzester Zeit ein sehr hohes Volumen erreichen. Die Firma Waymo hat zum Beispiel einen zwei Terabyte großen Datensatz, der während elf Fahrstunden gesammelt wurde, veröffentlicht <a class="footnote-reference brackets" href="#waymo" id="id5">5</a>. Daten, die mehr oder weniger kontinuierlich in hoher Geschwindigkeit generiert werden, nennt man auch <em>Streamingdaten</em>.</p>
<p>Eine besondere Schwierigkeit beim Umgang mit Streamingdaten besteht darin, dass diese oft in nahezu Echtzeit verarbeitet werden müssen. Beim autonomen Fahren ist dies sofort klar, schon alleine wegen der Sicherheit. Doch das gilt auch für viele andere Anwendungen, zum Beispiel für das Sortieren des Nachrichtenstreams in sozialen Netzwerken. Hier kommt zwar niemand zu schaden, die Nutzer würden einen Dienst aber schnell verlassen, wenn die Ladezeiten zu lang sind. Entsprechend müssen beim Umgang mit Streamingdaten in der Regel zwei Anforderungen gleichzeitig erfüllt werden: Daten müssen sehr schnell empfangen werden und dürfen dann auch nicht lange in einem Zwischenspeicher landen bzw. sich dort befinden, sondern müssen sofort verarbeitet und ausgewertet werden. Hierdurch ergibt sich eine Art inverse Korrelation zwischen der Geschwindigkeit und dem Datenvolumen: Je höher die Geschwindigkeit, desto weniger Daten reichen aus, um Daten zu Big Data werden zu lassen. Oder an einem Beispiel: Ein Gigabyte pro Tag zu verarbeiten ist einfacher als ein Gigabyte pro Sekunde.</p>
</div>
<div class="section" id="variety-vielfalt">
<h3><span class="section-number">1.1.3. </span>Variety / Vielfalt<a class="headerlink" href="#variety-vielfalt" title="Permalink to this headline">¶</a></h3>
<p>Die Vielfalt der Daten ist der dritte große Aspekt von Big Data. Mittlerweile ist die Analyse von Bildern, Videos und Texten zu einer normalen Anwendung geworden. Dies war jedoch noch nicht der Fall, als der Begriff Big Data geprägt wurde. Im Zeitraum um die Jahrtausendwende lagen die Daten, die analysiert werden sollten, üblicherweise strukturiert vor, zum Beispiel in relationalen Datenbanken. Die Daten waren entweder numerisch oder in feste Kategorien eingeteilt. Das änderte sich im Laufe der 2000er-Jahre, dadurch dass das Internet allgegenwärtig wurde und wir immer mehr Computertechnik in unseren Alltag übernommen haben, zum Beispiel in Form von Smartphones. Hier entstanden Daten eher auf unstrukturierte Weise, zum Beispiel durch Webseiten, die ad hoc von Nutzern erstellt wurden. Es ist daher kein Zufall, dass Google den Begriff Big Data und die damit verbundenen Technologien mitgeprägt hat: Die Indizierung des stetig wachsenden und komplexer werdenden Internets zwang dazu, die vorhandenen Techniken rapide weiterzuentwickeln. Hierbei mussten nicht nur immer größere Datenmengen verarbeitet werden, sondern vor allem eine Vielfalt von Datenformaten, insbesondere Text- und Bilddaten, später auch Videodaten.</p>
<p>Insgesamt gibt es viel mehr unstrukturierte Daten als strukturierte Daten. Dies wird üblicherweise als Pyramide dargestellt (<a class="reference internal" href="#fig-structures"><span class="std std-numref">Fig. 1.2</span></a>), in der zwischen <em>unstrukturierten</em>, <em>quasistrukturierten</em>, <em>semistrukturierten</em> und <em>strukturierten</em> Daten unterschieden wird.</p>
<div class="figure align-default" id="fig-structures">
<a class="reference internal image-reference" href="../_images/data_structures.png"><img alt="../_images/data_structures.png" src="../_images/data_structures.png" style="width: 400px;" /></a>
<p class="caption"><span class="caption-number">Fig. 1.2 </span><span class="caption-text">Datenpyramide</span><a class="headerlink" href="#fig-structures" title="Permalink to this image">¶</a></p>
</div>
<p>An der Spitze der Pyramide sind die strukturierten Daten, zum Beispiel Tabellen in relationalen Datenbanken, <em>Comma-Separated-Value-</em>(CSV-)Dateien und Ähnliches. Strukturierte Daten kann man im Normalfall direkt in ein Analysetool laden, ohne dass Vorverarbeitungsschritte notwendig sind. Die Vorverarbeitung beschränkt sich daher bei strukturierten Daten höchstens auf Aufgaben wie das Säubern der Daten, um beispielsweise ungültige Datenpunkte oder Ausreißer zu filtern.</p>
<p>Als Nächstes kommen die semistrukturierten Daten, zum Beispiel XML und JSON. Der Hauptunterschied zwischen strukturierten und semistrukturierten Daten ist die Flexibilität der Datenformate. Bei strukturierten Daten ist beispielsweise in der Regel der Typ einer Spalte fest definiert. Dies ist bei semistrukturierten Daten anders: Hier trifft man oftmals auf verschachtelte Strukturen, die man für die Analyse erst aufbrechen muss. Außerdem gibt es häufig optionale Felder, wodurch die Verarbeitung komplizierter werden kann. Dennoch kann man mit semistrukturierten Daten überwiegend einfach arbeiten, da diese auch ohne großen Aufwand in viele Analyseumgebungen importiert werden können.</p>
<p>Im Allgemeinen gilt für strukturierte und semistrukturierte Daten gemeinsam, dass es feste Datenformate und/oder Anfragesprachen gibt, mit denen man einfach die benötigten Informationen extrahieren und laden kann. Dies ist in den beiden unteren Ebenen der Pyramide nicht mehr der Fall. Quasistrukturierte Daten haben zwar eine fest definierte Struktur, es ist aber ein gewisser Aufwand erforderlich, um an die benötigten Informationen zu kommen. Als Beispiel betrachten wir die Ausgabe des Befehls <code class="docutils literal notranslate"><span class="pre">ls</span> <span class="pre">-l</span></code>, mit dem man sich in einem Linuxterminal die Dateien in einem Ordner anzeigen lassen kann.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">ls</span> -l
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>total 6792
drwxr-xr-x 1 sherbold sherbold     512 Mar 24 14:23 <span class=" -Color -Color-Bold -Color-Bold-Blue">data</span>/
-rw-r--r-- 1 sherbold sherbold    2957 May  5 14:30 howto.ipynb
drwxr-xr-x 1 sherbold sherbold     512 Apr 27 17:04 <span class=" -Color -Color-Bold -Color-Bold-Blue">images</span>/
-rw-r--r-- 1 sherbold sherbold   63683 May  6 11:52 kapitel_01.ipynb
-rw-r--r-- 1 sherbold sherbold  113117 May 10 10:11 kapitel_02.ipynb
-rw-r--r-- 1 sherbold sherbold   24576 May 10 10:08 kapitel_03.ipynb
-rw-r--r-- 1 sherbold sherbold  886609 May 10 10:10 kapitel_04.ipynb
-rw-r--r-- 1 sherbold sherbold   39543 May  6 16:44 kapitel_05.ipynb
-rw-r--r-- 1 sherbold sherbold 1664391 May  6 18:50 kapitel_06.ipynb
-rw-r--r-- 1 sherbold sherbold 2679078 May 10 09:05 kapitel_07.ipynb
-rw-r--r-- 1 sherbold sherbold  199328 May 10 09:23 kapitel_08.ipynb
-rw-r--r-- 1 sherbold sherbold  446103 May 10 09:39 kapitel_09.ipynb
-rw-r--r-- 1 sherbold sherbold  579843 May 10 09:50 kapitel_10.ipynb
-rw-r--r-- 1 sherbold sherbold  148082 May 10 09:58 kapitel_11.ipynb
-rw-r--r-- 1 sherbold sherbold   54300 May  6 12:11 kapitel_12.ipynb
-rw-r--r-- 1 sherbold sherbold    5967 May  6 15:16 kapitel_13.ipynb
-rw-r--r-- 1 sherbold sherbold    4927 May  5 14:30 notations.ipynb
-rw-r--r-- 1 sherbold sherbold    3887 May  6 11:59 vorwort.ipynb
</pre></div>
</div>
</div>
</div>
<p>Man sieht eine klare Struktur in den Daten: Die meisten Zeilen beinhalten die Benutzerrechte, gefolgt von der Anzahl der Symlinks auf die Datei, dem Benutzer und der Gruppe, die die Datei besitzen, der Dateigröße, dem Datum der letzten Änderung und zuletzt dem Namen. Diese Struktur kann man nutzen, um einen Parser zu schreiben, der die Daten einliest, zum Beispiel mithilfe von einem regulären Ausdruck. Wir können also eine Struktur über quasistrukturierte Daten legen, indem wir die Struktur durch einen Parser selbst definieren. Dies ist zwar mehr Aufwand als bei strukturierten und semistrukturierten Daten, aber man kommt dennoch zuverlässig an die benötigten Informationen. Trotzdem kann es sehr leicht passieren, dass sich die Struktur ändert und der selbst geschriebene Parser nicht mehr funktioniert. Daher ist das Lesen von quasistrukturierten Daten fehleranfällig, da man eventuell Sonderfälle übersieht oder sich das Datenformat ändern kann. Man sollte also den oft signifikanten Wartungsaufwand bei der Verarbeitung von quasistrukturierten Daten für die Nutzung im Produktivbetrieb berücksichtigen.</p>
<p>Die unstrukturierten Daten sind auf der untersten Ebene der Pyramide. Hier befindet sich der Großteil der Daten: Bilder, Videos und Text. Die Herausforderung bei diesen Daten ist es, eine Struktur zu bestimmen, die man später verarbeiten kann. Hier gibt es keine Faustformel, es hängt stattdessen von den konkreten Daten und der geplanten Anwendung ab. Hinzu kommt, dass unstrukturierte Daten häufig vermischt sind. Dieses Buch ist ein gutes Beispiel: Wir haben eine Mischung aus natürlicher Sprache, Bildern, Formatinformationen (z.B. Überschriften, Listen) und Quelltext.</p>
</div>
<div class="section" id="innovative-informationsverarbeitungsmethoden">
<h3><span class="section-number">1.1.4. </span>Innovative Informationsverarbeitungsmethoden<a class="headerlink" href="#innovative-informationsverarbeitungsmethoden" title="Permalink to this headline">¶</a></h3>
<p>Auch wenn die drei Vs als die zentralen Eigenschaften von Big Data angesehen werden, sind die anderen Teile der Definition auch wichtig, um zu verstehen, dass Big Data mehr ist als einfach nur viele Daten, die möglicherweise schnell generiert werden und verschiedene Formate haben. Der nächste Teil der Definition spricht von dem Bedarf an <em>innovativen Informationsverarbeitungsmethoden</em>. Das bedeutet, dass man für Big Data nicht einen normalen Arbeitsplatzrechner oder sogar ein traditionelles Batch-System in einem Großrechner, in dem sich viele Rechenknoten einen Speicher über das Netzwerk teilen, nutzen kann. Stattdessen ist die <em>Datenlokalität</em> (engl. <em>data locality</em>) wichtig, da man in der Regel keine Kopien der Daten über das Netzwerk erzeugen kann. Dies hat zu einer Transformation geführt, sodass es immer mehr Infrastrukturen gibt, in denen Rechenkraft und schneller, verteilter Speicher direkt integriert sind. Als Big Data ein neues Konzept war, gab es solche Technologien noch nicht. Heutzutage hat man viele Möglichkeiten, allein bei der Apache Foundation <a class="footnote-reference brackets" href="#apache" id="id6">6</a> gibt es unter anderem Hadoop, Spark, Storm, Kafka, Cassandra, Hive, HBase, Giraph und viele weitere Technologien, die hochprofessionell als Open Source entwickelt und von vielen Unternehmen zur Verarbeitung von Big Data eingesetzt werden.</p>
</div>
<div class="section" id="wissen-generieren-entscheidungen-treffen-prozesse-automatisieren">
<h3><span class="section-number">1.1.5. </span>Wissen generieren, Entscheidungen treffen, Prozesse automatisieren.<a class="headerlink" href="#wissen-generieren-entscheidungen-treffen-prozesse-automatisieren" title="Permalink to this headline">¶</a></h3>
<p>Der letzte Teil der Big-Data-Definition bedeutet, dass Big Data kein Selbstzweck ist. Man spricht nur dann von Big Data, wenn man die Daten auch zum Erreichen eines Ziels nutzt. Ziele können der reine Erkenntnisgewinn sein, die Unterstützung der Entscheidungsfindung oder sogar die Automatisierung ganzer Geschäftsprozesse. Dieser Aspekt der Definition ist so wichtig, dass er häufig als weiteres V betrachtet wird: <em>Value</em>.</p>
</div>
<div class="section" id="noch-mehr-vs">
<h3><span class="section-number">1.1.6. </span>Noch mehr Vs<a class="headerlink" href="#noch-mehr-vs" title="Permalink to this headline">¶</a></h3>
<p>Die Definition von Gartner, die wir hier im Buch verwenden, hat “nur” drei Vs. Die Definition von Big Data durch Wörter, die mit V anfangen, ist jedoch so populär, dass es verschiedene Erweiterungen gibt mit bis zu 42 (!) Vs <a class="footnote-reference brackets" href="#v" id="id7">7</a>. Die 42 Vs sollte man aber eher als Satire verstehen, die zeigen soll, dass mehr Vs nicht immer zu einer besseren Definition führen. Nichtsdestotrotz gibt es seriöse Definitionen mit bis zu zehn Vs <a class="footnote-reference brackets" href="#id15" id="id8">8</a>.  Ein zusätzliches V hatten wir bereits: <em>Value</em>, also die Wertschöpfung durch Big Data. Die <em>Korrektheit</em> (engl. <em>veracity</em>) ist ein weiteres V, was häufig als hochrelevant eingeschätzt wird. Je mehr Daten man auswertet, desto schwieriger wird es, sicherzustellen, dass die Daten zuverlässig sind und sich Ergebnisse reproduzieren lassen. Dies ist insbesondere dann schwer, wenn sich die Datenquellen oft ändern, zum Beispiel bei der Analyse von Nachrichten oder der sozialen Medien. Volume, Velocity, Variety, Veracity und Value zusammen ergeben die Fünf-V-Definition von Big Data, die stark verbreitet ist. Weitere Vs betrachten wir an dieser Stelle nicht mehr.</p>
</div>
</div>
<div class="section" id="einfuhrung-in-data-science">
<h2><span class="section-number">1.2. </span>Einführung in Data Science<a class="headerlink" href="#einfuhrung-in-data-science" title="Permalink to this headline">¶</a></h2>
<p>Auch wenn der Begriff <em>Data Science</em> als Buzzword sehr populär ist, existiert noch keine allgemein akzeptierte Definition. Hierfür gibt es vermutlich zwei Gründe: Erstens ist der Begriff sehr generisch, sodass jede Verwendung von Daten, die in irgendeiner Form als “wissenschaftlich” betrachtet wird, als Data Science bezeichnet werden kann. Und zweitens gibt es einen großen Hype um diesen Begriff, weshalb Firmen, Fördermittelgeber und öffentliche Institutionen mit diesem Begriff Werbung für sich betreiben wollen.</p>
<p>Aus diesem Grund können wir hier leider auch keine kurze und einprägsame Definition für diesen Begriff geben. Stattdessen betrachten wir, welche Konzepte unter anderem als Data Science angesehen werden, und schauen uns Beispiele für Data-Science-Anwendungen an.</p>
<div class="section" id="was-gehort-zu-data-science">
<h3><span class="section-number">1.2.1. </span>Was gehört zu Data Science?<a class="headerlink" href="#was-gehort-zu-data-science" title="Permalink to this headline">¶</a></h3>
<p>Data Science kombiniert Methoden aus der Mathematik, Statistik und Informatik mit dem Ziel , datengetriebene Anwendungen zu entwickeln oder Wissen zu generieren. Die Wertschöpfung ist also sehr ähnlich zu Big Data. Der Hauptunterschied zwischen den Begriffen liegt auf dem Fokus auf große Datenmengen bei Big Data, der bei Data Science nicht gegeben sein muss.</p>
<p>Mathematik ist häufig das Fundament, auf dem die Datenanalyse definiert wird. Die Modelle über die Daten, die erstellt werden, sind im Endeffekt nichts anderes als eine mathematische Beschreibung von Aspekten der Daten. Man könnte also Data Science als mathematische Modellierung verstehen. Die Rolle der Mathematik ist jedoch größer als die einer “Beschreibungssprache” für Modelle. Teilgebiete der Mathematik liefern die Methoden, die man braucht, um Modelle zu bestimmen.</p>
<ul class="simple">
<li><p><em>Optimierung</em> beschreibt, wie man die optimale Lösung für eine Zielfunktion findet, sodass die gefundene Lösung gewisse Nebenbedingungen erfüllt. Die Zielfunktion und die Nebenbedingungen werden bei Data Science häufig direkt aus den Daten ermittelt, sodass die Lösung optimal für die gegebenen Daten ist.</p></li>
<li><p><em>Stochastik</em> ist ein Teilgebiet der Mathematik, das sich mit zufälligen Verhalten durch Zufallsvariablen und stochastischen Prozessen befasst. Stochastik bildet daher eine wichtige Grundlage für die Theorie des maschinellen Lernens, und stochastische Modelle werden häufig genutzt, um Daten zu beschreiben.</p></li>
<li><p>Ohne die <em>Geometrie</em> könnte man keine Daten, die räumlich verteilt sind, analysieren, zum Beispiel geografische Daten oder der 3-dimensionale Raum vor einem Fahrzeug.</p></li>
<li><p><em>Wissenschaftliches Rechnen</em> wird immer häufiger nicht nur genutzt, um Daten für Analysen zu simulieren, sondern auch, um Modelle über Daten durch Simulation zu bestimmen.</p></li>
</ul>
<p>Die Statistik befasst sich mit der Analyse von Daten durch Stichproben, zum Beispiel das Schätzen der den Daten zugrunde liegenden Verteilungen, Zeitreihenanalysen oder die Entwicklung von statistischen Tests, mit denen man auswerten kann, ob Effekte zufällig oder signifikant sind.</p>
<ul class="simple">
<li><p><em>Lineare Modelle</em> sind eine vielfältig einsetzbare Methode, um Daten zu beschreiben, um daraus Zusammenhänge zu erkennen oder Trends zu ermitteln.</p></li>
<li><p><em>Inferenz</em> ist ein ähnliches Verfahren, nur dass Wahrscheinlichkeitsverteilungen statt linearer Modelle genutzt werden, um die Daten zu beschreiben.</p></li>
<li><p><em>Zeitreihenanalyse</em> nutzt die interne Struktur von Daten, die über die Zeit gemessen wurden. Hierbei werden zum Beispiel saisonale Effekte oder andere sich wiederholende Muster genutzt, um die Struktur der Zeitreihe zu modellieren und zukünftige Werte vorherzusagen.</p></li>
</ul>
<p>Ohne die Informatik, wären die mathematischen und statistischen Verfahren nicht durch Computer ausführbar. Doch auch die theoretische Informatik liefert wichtige Grundlagen für Data Science.</p>
<ul class="simple">
<li><p><em>Datenstrukturen und Algorithmen</em> sind die Grundlage von jeder effizienten Umsetzung von Algorithmen. Ohne das Verständnis von Datenstrukturen, wie Bäumen, Hashmaps und Listen, sowie von der Laufzeitkomplexität von Algorithmen wären Datenanalysemethoden nicht skalierbar auf große Datenmengen.</p></li>
<li><p>Die <em>Informationstheorie</em> liefert das nötige Verständnis über die Entropie (Unsicherheit in den Daten) und gemeinsame Information von Daten und ist damit die Grundlage für viele Algorithmen des maschinellen Lernens.</p></li>
<li><p><em>Datenbanken</em> werden benötigt, um Daten effizient zu speichern und zugreifbar zu machen. SQL ist als Anfragesprache nicht nur bei relationalen Datenbanken, sondern auch bei NoSQL-Datenbanken allgegenwärtig.</p></li>
<li><p><em>Paralleles und verteiltes Rechnen</em> sind notwendig, um das Arbeiten mit großen Datenmengen und hoher Rechenkraft zu ermöglichen.</p></li>
<li><p>Die klassische künstliche Intelligenz liefert die Grundlagen für die logische Modellierung und die Definition von Regelsystemen für viele Data-Science-Anwendungen. In diesem Buch unterscheiden wir explizit zwischen künstlicher Intelligenz und maschinellem Lernen. Wir benutzen den Begriff <em>künstliche Intelligenz</em>, um Anwendungen wie Deep Blue <a class="footnote-reference brackets" href="#deepblue" id="id9">9</a>, die regelbasierte Schach-Engine, die als erster Computer Gary Kasparow im Schach besiegt hat, zu beschreiben.</p></li>
<li><p>Softwaretechnik ist für die Operationalisierung von Anwendungen und das Management von Data-Science-Projekten notwendig.</p></li>
</ul>
<p>Und zuletzt gibt es natürlich noch das <em>maschinelle Lernen</em>, was häufig auch als definierender Aspekt von Data Science gesehen wird. Das maschinelle Lernen kombiniert Mathematik, Statistik und Informatik auf geschickte Art und Weise. Je nachdem welche Methoden man betrachtet, können alle drei Disziplinen das maschinelle Lernen für sich beanspruchen. Durch maschinelles Lernen versucht man, Wissen aus Daten zu gewinnen, sodass das Wissen die Daten nicht nur beschreibt, sondern auch auf weitere Daten und Applikationen angewendet werden kann, zum Beispiel durch neuronale Netze, Entscheidungsbäume und Mustererkennung.</p>
</div>
<div class="section" id="beispielanwendungen">
<h3><span class="section-number">1.2.2. </span>Beispielanwendungen<a class="headerlink" href="#beispielanwendungen" title="Permalink to this headline">¶</a></h3>
<p>So unterschiedlich wie die Grundlagen von Data Science sind, so verschieden sind auch die Anwendungen in der Forschung, Industrie und Gesellschaft. Hier sind fünf kurze Beispiele:</p>
<ul class="simple">
<li><p><em>Alpha Go</em> ist ein Beispiel für ein intelligentes selbstlernendes System. Vor einigen Jahren überraschte Alpha Go die Fachwelt, weil es scheinbar aus dem Nichts kam und einen der weltbesten Spieler im Go besiegte. Go gilt als besonders schwieriges Spiel, zum Beispiel im Verhältnis zu Schach, und Computer waren bis dahin gerade mal auf dem Niveau von Amateuren und stellten keine Herausforderung für professionelle Spieler dar. Alpha Go kombinierte klassische regelbasierte künstliche Intelligenz mit statistischen Monte-Carlo-Simulationen und selbstlernenden neuronalen Netzen, um dies zu erreichen.</p></li>
<li><p>Die <em>Robotik</em> nutzt maschinelles Lernen, um den Robotern beizubringen, sich zu bewegen. Mit der Zeit können Roboter zum Beispiel lernen, durch welche Bewegungen sie das Umfallen verhindern können <a class="footnote-reference brackets" href="#robots" id="id10">10</a>.</p></li>
<li><p>Marketing setzt auf Data Science, um im Internet gezielt Werbung schalten zu können. Die dahinter liegende Industrie erwirtschaftet Milliarden, indem Nutzern relevante Werbung basierend auf ihrem Verhalten im Internet gezeigt wird.</p></li>
<li><p>In der <em>Medizin</em> werden Daten immer häufiger genutzt, um Entscheidungen zu unterstützen. IBM Watson, das erste Computerprogramm, das Menschen im Jeopardy besiegt hat <a class="footnote-reference brackets" href="#jeopardy" id="id11">11</a>, wird heutzutage zum Beispiel auch eingesetzt, um geeignete Krebstherapien auszuwählen <a class="footnote-reference brackets" href="#cancer1" id="id12">12</a>. (Auch wenn das nicht so gut klappt, wie man es sich ursprünglich erhofft hat <a class="footnote-reference brackets" href="#cancer2" id="id13">13</a>.)</p></li>
<li><p>Im <em>autonomen Fahren</em> wird maschinelles Lernen für verschiedene Aufgaben genutzt, zum Beispiel für die Erkennung von Objekten, wie Verkehrsschildern, anderen Autos oder Fußgängern.</p></li>
</ul>
</div>
</div>
<div class="section" id="fahigkeiten-von-data-scientists">
<h2><span class="section-number">1.3. </span>Fähigkeiten von Data Scientists<a class="headerlink" href="#fahigkeiten-von-data-scientists" title="Permalink to this headline">¶</a></h2>
<p>Data Scientists sind weder Informatikerinnen, Mathematikerinnen, Statistikerinnen oder Domänenexpertinnen. Der perfekte Data Scientist bringt eine Kombination von allem als Fähigkeiten mit:</p>
<ul class="simple">
<li><p>Gute mathematische Fähigkeiten, insbesondere über Optimierung und Stochastik</p></li>
<li><p>Sicherer Umgang mit Methoden aus der Statistik, insbesondere Regression, statistische Tests und Inferenz</p></li>
<li><p>Gute Programmierkenntnisse, sicherer Umgang mit Datenbanken, Datenstrukturen, parallelem Rechnen und Big-Data-Technologien.</p></li>
<li><p>Problemloser Wechsel zwischen den obigen Fähigkeiten und sicherer Umgang mit Technologien, die in der Schnittstelle liegen, insbesondere dem maschinellen Lernen</p></li>
<li><p>Genug Wissen über die Domäne, um die Daten zu verstehen, Fragestellungen zu definieren und zu erarbeiten, ob und wie diese Fragen mithilfe von Daten beantwortet werden können</p></li>
</ul>
<p>Außerdem müssen Data Scientists teamfähig sein, um mit Domänenexpertinnen auf der einen Seite und technischen Expertinnen auf der anderen Seite zusammenarbeiten zu können. Die Domänenexpertinnen helfen den Data Scientists, die Daten, Fragestellungen und Projektziele zu verstehen. Die technischen Expertinnen helfen bei der Umsetzung von Projekten, insbesondere bei der Operationalisierung.</p>
<p>Nicht zuletzt sollten Data Scientists zwar den notwendigen Enthusiasmus mitbringen, um sich für die Arbeit mit Daten begeistern zu können, aber auch die notwendige Skepsis, um die Problemstellung nach wissenschaftlichen Prinzipien anzugehen. Das heißt insbesondere auch, dass man alles tun sollte, um auszuschließen, dass etwas nur aus Zufall funktioniert, und rigoros überprüfen muss, ob Modelle wirklich wie gewünscht funktionieren.</p>
<p>Wenn man sich dieses Fähigkeitsprofil anschaut, wird schnell klar, dass die Anzahl der Personen, die alles mitbringen, begrenzt ist. Microsoft Research hat sich daher mit der Fragestellung befasst, was Data Scientists im Arbeitsalltag leisten und welche Arten von Data Scientists es gibt <a class="footnote-reference brackets" href="#mssurvey" id="id14">14</a>. Hierbei wurden acht Arten von Data Scientists bestimmt:</p>
<ul class="simple">
<li><p><em>Polymath</em> sind die Alleskönner, die das gesamte oben beschriebene Profil erfüllen und alles von der zugrunde liegenden Mathematik bis hin zu den Big-Data-Infrastrukturen verstehen.</p></li>
<li><p><em>Data Evangelists</em> analysieren selbst Daten, verbreiten aber auch die Erkenntnisse und Modelle. Sie setzen sich insbesondere auch dafür ein, dass aus ihren Modellen Produkte entwickelt werden.</p></li>
<li><p><em>Data Preparers</em> sammeln Daten und bereiten diese für die Analyse auf.</p></li>
<li><p><em>Data Analyzers</em> analysieren Daten, die ihnen zur Verfügung gestellt werden.</p></li>
<li><p><em>Data Shapers</em> kombinieren die beiden vorigen Rollen, das heißt, sie sammeln und analysieren Daten.</p></li>
<li><p><em>Platform Builders</em> sammeln nicht nur Daten, sondern entwickeln und administrieren ganze Plattformen, die zur Datensammlung und Analyse genutzt werden können.</p></li>
<li><p><em>Moonlighters 50%</em> und <em>Moonlighters 20%</em> sind Teilzeit-Data-Scientists, die zwar auch eine Data-Science-Rolle ausfüllen, aber nur als ein Bruchteil ihrer täglichen Arbeit.</p></li>
<li><p><em>Insight Actors</em> sind die Nutzer von Analysen und Modellen.</p></li>
</ul>
<hr class="footnotes docutils" />
<dl class="footnote brackets">
<dt class="label" id="gartner"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p><a class="reference external" href="https://www.gartner.com/en/information-technology/glossary/big-data">https://www.gartner.com/en/information-technology/glossary/big-data</a></p>
</dd>
<dt class="label" id="mapreducepaper"><span class="brackets"><a class="fn-backref" href="#id2">2</a></span></dt>
<dd><p><a class="reference external" href="https://doi.org/10.1145/1327452.1327492">https://doi.org/10.1145/1327452.1327492</a></p>
</dd>
<dt class="label" id="sneakernet"><span class="brackets"><a class="fn-backref" href="#id3">3</a></span></dt>
<dd><p><a class="reference external" href="https://en.wikipedia.org/wiki/Sneakernet">https://en.wikipedia.org/wiki/Sneakernet</a></p>
</dd>
<dt class="label" id="blackhole"><span class="brackets"><a class="fn-backref" href="#id4">4</a></span></dt>
<dd><p><a class="reference external" href="https://www.extremetech.com/extreme/289423-it-took-half-a-ton-of-hard-drives-to-store-eht-black-hole-image-data">https://www.extremetech.com/extreme/289423-it-took-half-a-ton-of-hard-drives-to-store-eht-black-hole-image-data</a></p>
</dd>
<dt class="label" id="waymo"><span class="brackets"><a class="fn-backref" href="#id5">5</a></span></dt>
<dd><p><a class="reference external" href="https://waymo.com/open/">https://waymo.com/open/</a></p>
</dd>
<dt class="label" id="apache"><span class="brackets"><a class="fn-backref" href="#id6">6</a></span></dt>
<dd><p><a class="reference external" href="https://www.apache.org/">https://www.apache.org/</a></p>
</dd>
<dt class="label" id="v"><span class="brackets"><a class="fn-backref" href="#id7">7</a></span></dt>
<dd><p><a class="reference external" href="https://www.kdnuggets.com/2017/04/42-vs-big-data-data-science.html">https://www.kdnuggets.com/2017/04/42-vs-big-data-data-science.html</a></p>
</dd>
<dt class="label" id="id15"><span class="brackets"><a class="fn-backref" href="#id8">8</a></span></dt>
<dd><p><a class="reference external" href="https://tdwi.org/articles/2017/02/08/10-vs-of-big-data.aspx">https://tdwi.org/articles/2017/02/08/10-vs-of-big-data.aspx</a></p>
</dd>
<dt class="label" id="deepblue"><span class="brackets"><a class="fn-backref" href="#id9">9</a></span></dt>
<dd><p><a class="reference external" href="https://doi.org/10.1007/978-1-4612-2260-6">https://doi.org/10.1007/978-1-4612-2260-6</a></p>
</dd>
<dt class="label" id="robots"><span class="brackets"><a class="fn-backref" href="#id10">10</a></span></dt>
<dd><p><a class="reference external" href="https://doi.org/10.1126/scirobotics.aau5872">https://doi.org/10.1126/scirobotics.aau5872</a></p>
</dd>
<dt class="label" id="jeopardy"><span class="brackets"><a class="fn-backref" href="#id11">11</a></span></dt>
<dd><p><a class="reference external" href="https://www.ibm.com/ibm/history/ibm100/us/en/icons/watson/">https://www.ibm.com/ibm/history/ibm100/us/en/icons/watson/</a></p>
</dd>
<dt class="label" id="cancer1"><span class="brackets"><a class="fn-backref" href="#id12">12</a></span></dt>
<dd><p><a class="reference external" href="https://www.ibm.com/marketplace/clinical-decision-support-oncology">https://www.ibm.com/marketplace/clinical-decision-support-oncology</a></p>
</dd>
<dt class="label" id="cancer2"><span class="brackets"><a class="fn-backref" href="#id13">13</a></span></dt>
<dd><p><a class="reference external" href="https://spectrum.ieee.org/biomedical/diagnostics/how-ibm-watson-overpromised-and-underdelivered-on-ai-health-care">https://spectrum.ieee.org/biomedical/diagnostics/how-ibm-watson-overpromised-and-underdelivered-on-ai-health-care</a></p>
</dd>
<dt class="label" id="mssurvey"><span class="brackets"><a class="fn-backref" href="#id14">14</a></span></dt>
<dd><p><a class="reference external" href="https://doi.org/10.1109/TSE.2017.2754374">https://doi.org/10.1109/TSE.2017.2754374</a></p>
</dd>
</dl>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./chapters"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="vorwort.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title">WICHTIG: Arbeitsversion</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="kapitel_02.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title"><span class="section-number">2. </span>Der Prozess von Data-Science-Projekten</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Steffen Herbold<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>