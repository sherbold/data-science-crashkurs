
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>3. Allgemeines zur Datenanalyse &#8212; Data Science Crashkurs - Eine interaktive und praktische Einführung</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.acff12b8f9c144ce68a297486a2fa670.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="4. Erkunden der Daten" href="kapitel_04.html" />
    <link rel="prev" title="2. Der Prozess von Data Science Projekten" href="kapitel_02.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Data Science Crashkurs - Eine interaktive und praktische Einführung</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="vorwort.html">
   Vorwort
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Kapitel
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="kapitel_01.html">
   1. Big Data und Data Science
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kapitel_02.html">
   2. Der Prozess von Data Science Projekten
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   3. Allgemeines zur Datenanalyse
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kapitel_04.html">
   4. Erkunden der Daten
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kapitel_05.html">
   5. Assoziationsregeln
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kapitel_06.html">
   6. Clusteranalyse
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kapitel_07.html">
   7. Klassifikation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kapitel_08.html">
   8. Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kapitel_09.html">
   9. Zeitreihenanalyse
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kapitel_10.html">
   10. Textmining
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kapitel_11.html">
   11. Statistik
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kapitel_12.html">
   12. Big Data Processing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kapitel_13.html">
   13. Weiterführende Konzepte
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Appendix
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="howto.html">
   Selber Ausführen
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="notations.html">
   Notationen
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/chapters/kapitel_03.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/sherbold/einfuehrung-in-data-science"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/sherbold/einfuehrung-in-data-science/main?urlpath=tree/content/chapters/kapitel_03.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#das-no-free-lunch-theorem">
   3.1. Das No Free Lunch Theorem
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#definition-von-maschinellem-lernen">
   3.2. Definition von maschinellem Lernen
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#merkmale">
   3.3. Merkmale
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#trainings-und-testdaten">
   3.4. Trainings- und Testdaten
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#kategorien-von-algorithmen">
   3.5. Kategorien von Algorithmen
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ubung">
   3.6. Übung
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#laden-von-csv-daten">
     3.6.1. Laden von CSV Daten
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entfernen-von-merkmalen">
     3.6.2. Entfernen von Merkmalen
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#entfernen-von-instanzen-mit-fehlenden-werten">
     3.6.3. Entfernen von Instanzen mit fehlenden Werten
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#rechnen-mit-dataframes">
     3.6.4. Rechnen mit Dataframes
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#zusammenfugen-von-dataframes">
     3.6.5. Zusammenfügen von Dataframes
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#auswahl-von-teilmengen">
     3.6.6. Auswahl von Teilmengen
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="allgemeines-zur-datenanalyse">
<h1><span class="section-number">3. </span>Allgemeines zur Datenanalyse<a class="headerlink" href="#allgemeines-zur-datenanalyse" title="Permalink to this headline">¶</a></h1>
<p>Bevor wir uns in die Algorithmen zur Modellierung mit Hilfe von Daten stürzen, benötigen wir noch einige Grundlagen. Hierbei handelt es sich um allgemeine Konzepte, die nicht von einer bestimmten Art der Analyse oder Daten abhängen und die wir immer wieder benötigen. Außerdem geben wir in diesem Kapitel auch einen Überblick über die Arten von Algorithmen die es gibt.</p>
<div class="section" id="das-no-free-lunch-theorem">
<h2><span class="section-number">3.1. </span>Das No Free Lunch Theorem<a class="headerlink" href="#das-no-free-lunch-theorem" title="Permalink to this headline">¶</a></h2>
<p>Die erste ist eine fundamentale Aussage über Optimierungsalgorithmen, das <em>No Free Lunch Theorem</em> (NFL). Das Theorem selbst ist sehr theoretisch, wenn Sie sich nur für die (sehr wichtigen!) praktischen Auswirkungen interessieren, springen Sie einfach direkt zur umgangssprachlichen Definition. Die mathematische Formulierung des NFL lautet wie folgt.</p>
<blockquote>
<div><p><strong>No Free Lunch Theorem:</strong></p>
<p>Sei <span class="math notranslate nohighlight">\(d_m^y\)</span> eine geordnete Menge der Kardinalität <span class="math notranslate nohighlight">\(m\)</span> mit Kostenwerten <span class="math notranslate nohighlight">\(y \in Y\)</span>. Sei <span class="math notranslate nohighlight">\(f: X \to Y\)</span> eine Funktion die optimiert werden soll. Sei <span class="math notranslate nohighlight">\(P(d_m^y|f, m, a)\)</span> die bedinge Wahrscheinlichkeit die Kosten <span class="math notranslate nohighlight">\(d_m^y\)</span> durch <span class="math notranslate nohighlight">\(m\)</span> wiederholte Ausführungen des Algorithmus <span class="math notranslate nohighlight">\(a\)</span> für die Funktion <span class="math notranslate nohighlight">\(f\)</span> zu beobachten.</p>
<p>Für jedes Paar von Algorithmen <span class="math notranslate nohighlight">\(a_1\)</span> und <span class="math notranslate nohighlight">\(a_2\)</span> gilt:</p>
<div class="math notranslate nohighlight">
\[\sum_f P(d_m^y|f, m, a_1) = \sum_f P(d_m^y|f, m, a_2)\]</div>
</div></blockquote>
<p>Einen Beweis für das Theorem findet man in der Literatur <a class="footnote-reference brackets" href="#nfl" id="id1">1</a>. Die Gleichung des NFL besagt das die Summe der Wahrscheinlichkeiten bestimmte Kosten zu erhalten gleich ist, wenn man die Gesamtheit aller Funktionen <span class="math notranslate nohighlight">\(f\)</span> betrachtet, unabhängig vom Algorithmus. Einfacher formuliert bedeutet das NFL:</p>
<blockquote>
<div><p><strong>No Free Lunch Theorem (Umgangssprachlich):</strong></p>
<p>Alle Algorithmen sind gleich, wenn man alle möglichen Optimierungsprobleme betrachtet.</p>
</div></blockquote>
<p>Diese Aussage entspricht nicht der Intuition, die man durch das praktische Arbeiten mit Daten hat. Für bestimmte Probleme merkt man sehr wohl, das einige Algorithmen besser sind als andere. Dies wird durch das NFL aber auch gar nicht ausgeschlossen, im Gegenteil. Ein Algorithmus kann durchaus für einige Funktionen <span class="math notranslate nohighlight">\(f\)</span> besser sein als andere Algorithmen. Aus dem NFL folgt aber, dass dieser Algorithmus dann auf allen anderen Problemen unterdurchschnittlich sein muss. Das ist auch die wichtige praktische Konsequenz des NFL: <em>Es gibt keinen Algorithmus, der für alle Probleme optimal ist!</em> Stattdessen hängt der optimale Algorithmus zur Lösung eines Problems vom Problem selbst ab. Daher auch der Name des Theorems: Es gibt kein “Gratisessen”, also einen Algorithmus für alle Probleme. Stattdessen müssen sich Data Scientist ihr Essen verdienen, in dem sie passende Algorithmen kennen und auswählen.</p>
<p>Das heißt natürlich auch, dass es nicht ausreicht sich auf eine bestimmte Art von Algorithmus zu spezialisieren. Dieser Algorithmus kann mathematisch beweisbar gar nicht in jeder Situation die beste Wahl sein. Die Falle in die man tappen könnte ist, dass man nicht mehr den Algorithmus an das Problem anpasst, sondern das Problem an den Algorithmus. Denn wenn man einen Hammer hat, sieht manchmal alles aus wie ein Nagel. Stattdessen sollten wir eine ganze Werkzeugbox an Algorithmen kennen. Nur dann können wir basierend auf der Problemstellung, den zur Verfügung stehenden Daten und unserer Erfahrung den am besten geeigneten Algorithmus auswählen. Dies lernt man nicht über Nacht, sondern nur aus der Erfahrung von vielen Projekten in denen man mit verschiedenen Datensätzen und Methoden arbeitet.</p>
</div>
<div class="section" id="definition-von-maschinellem-lernen">
<h2><span class="section-number">3.2. </span>Definition von maschinellem Lernen<a class="headerlink" href="#definition-von-maschinellem-lernen" title="Permalink to this headline">¶</a></h2>
<p>Maschinelles Lernen ist derzeit eines der heißesten Themen in der Informatik, da es in den letzten Jahren große Fortschritte bei der Lösung von praxisrelevanten Problemen durch die immer höher werdende  Rechenkraft, die größeren Datenmengen die zur Verfügung stehen, und innovatives Design von Lernalgorithmen, gab. Einige Problem die noch vor wenigen Jahren als extrem schwierig galten, sind jetzt durch maschinelles Lernen gelöst (siehe <a class="reference internal" href="kapitel_01.html"><span class="doc std std-doc">Kapitel 1</span></a>). Wenn man sich näher mit dem maschinellen Lernen beschäftigen möchte, muss man zuerst die Bedeutung des Begriffs verstehen. Es gibt viele Definition in der Literatur. Eine sehr mächtige und gleichzeitig intuitive kommt von Tom Mitchel <a class="footnote-reference brackets" href="#mitchel" id="id2">2</a>:</p>
<blockquote>
<div><p><strong>Definition von maschinellem Lernen:</strong></p>
<p>Ein Computerprogramm lernt aus Erfahrung <span class="math notranslate nohighlight">\(E\)</span> in Bezug auf eine Klasse von Aufgaben <span class="math notranslate nohighlight">\(T\)</span> und ein Gütemaß <span class="math notranslate nohighlight">\(P\)</span>, wenn die Güte der Lösungen von <span class="math notranslate nohighlight">\(T\)</span> gemessen durch <span class="math notranslate nohighlight">\(P\)</span> sich mit mehr Erfahrung <span class="math notranslate nohighlight">\(E\)</span> verbessert.</p>
</div></blockquote>
<p>Auf den ersten Blick wirkt diese Definition sehr abstrakt wirkt und ist schwer zu lesen. Insbesondere die abstrakten Begriffe von <em>Erfahrung</em>, einer <em>Klasse von Aufgaben</em>, und der <em>Güte</em> sind intuitiv in diesem Zusammenhang schwer einzuordnen. Das ist aber der Grund, weshalb die Definition so gut ist: Maschinelles Lernen ist ein sehr vielseitiges Gebiet, was anders kaum zu fassen ist. Außerdem ist die Definition nur auf den ersten Blick komplex. Bei einer genaueren  Betrachtung was mit Erfahrung, Aufgaben, und Güte gemeint ist, erscheint die Definition sehr naheliegend.</p>
<ul class="simple">
<li><p>Die <em>Erfahrung</em> ist (im Normalfall) unser Datensatz. Je mehr Daten wir haben, desto mehr Erfahrung haben wir. Es gibt außerdem auch selbst-lernende System, die keine externen Daten benötigen und die stattdessen ihre eigenen Daten generieren, wie AlphaZero <a class="footnote-reference brackets" href="#alphazero" id="id3">3</a>, das durch das Spielen gegen sich selbst lernt. In diesem Fall steigt die Erfahrung mit jedem Spiel.</p></li>
<li><p>Die <em>Aufgaben</em> sind nichts anderes als die Probleme, die wir mit maschinellem Lernen lösen möchten. Wir wollen Fußgänger erkennen, damit diese von ihrem autonomen Fahrzeug nicht überfahren werden? Wir wollen Spiele spielen und gewinnen? Wir wollen das die Besucher unserer Website auf die Werbung klicken? Das sind die Aufgaben. Im Allgemeinen ist die Aufgabe eng verwandt mit dem Anwendungsfalls und den Projektzielen. Etwas Abstrakter kann man Klassen von Aufgaben auf Kategorien von Algorithmen abbilden, wie wir am Ende dieses Kapitels sehen werden.</p></li>
<li><p>Die <em>Gütemaße</em> messen wie gut die Aufgabe erfüllt wird. Das könnte zum Beispiel die Anzahl der korrekt erkannten Fußgänger, der gewonnen Spiele oder die Zahl der Klicks auf Werbung sein.</p></li>
</ul>
<p>Mit diesem Wissen erscheint die Definition ganz einfach: Wir betrachten einfach Algorithmen, die besser werden, wenn ihnen mehr Daten zur Verfügung stehen.</p>
</div>
<div class="section" id="merkmale">
<h2><span class="section-number">3.3. </span>Merkmale<a class="headerlink" href="#merkmale" title="Permalink to this headline">¶</a></h2>
<p>Im letzten Kapitel haben wir bereits oft von <em>Merkmalen</em> (engl. <em>feature</em>) gesprochen, ohne jedoch genau zu Erklären was wir damit eigentlich meinen. Die Merkmale sind eine Kernkomponente von maschinellem Lernen. Die Bedeutung von Merkmalen kann man sich gut an einem Beispiel verdeutlichen. Wenn wir uns <a class="reference internal" href="#fig-whale"><span class="std std-numref">Fig. 3.1</span></a> angucken, erkennen wir sofort, dass es sich um einen Wal handelt. Wie genau wir als Menschen erkennen, dass es sich um einen Wal handelt ist nicht abschließend geklärt und immer noch der Gegenstand der Forschung. Nichtsdestotrotz nehmen wir hier an, dass wir verschiedene Aspekte vom Bild erkennen und Aufgrund der Aspekte dann zur Erkenntnis gelangen, dass es sich um einen Wal handelt. Man könnte zum Beispiel erkennen, dass sich ein etwa <em>ovales</em> Objekt im Vordergrund befindet, welches <em>oben schwarz und unten weiß</em> ist, das <em>Flossen hat</em> und das der <em>Hintergrund blau</em> ist. Das alles sind <em>Merkmale</em> des Bilds.</p>
<div class="figure align-default" id="fig-whale">
<a class="reference internal image-reference" href="../_images/whale.png"><img alt="../_images/whale.png" src="../_images/whale.png" style="width: 400px;" /></a>
<p class="caption"><span class="caption-number">Fig. 3.1 </span><span class="caption-text">Bild von einem Wal.</span><a class="headerlink" href="#fig-whale" title="Permalink to this image">¶</a></p>
</div>
<p>Und so funktioniert auch maschinelles Lernen: Schlussfolgerungen über Objekte werden anhand ihrer Merkmale gezogen. Formal haben wir einen <em>Objektraum</em> <span class="math notranslate nohighlight">\(O\)</span> mit Objekten aus der realen Welt und einen <em>Merkmalsraum</em> (engl. <em>feaature space</em>) <span class="math notranslate nohighlight">\(\mathcal{F}\)</span> mit Beschreibungen der Objekte durch ihre Merkmale. Eine <em>Feature Map</em> <span class="math notranslate nohighlight">\(\phi: 0 \to \mathcal{F}\)</span> bildet die Objekte auf ihre Repräsentation im Merkmalsraum ab. Für unser Walbild ist der Objektraum <span class="math notranslate nohighlight">\(O\)</span> die Menge der Bilder und der Merkmalsraum hätte fünf Dimensionen: Form, Farbe oben, Farbe unten, Hintergrundfarbe, Flossen. Die Represenation des Bilds im Merkmalsraum wäre daher <span class="math notranslate nohighlight">\(\phi(Walbild) = (Oval, Schwarz, Wei\text{ß}, Blau, Ja)\)</span>.</p>
<p>Es gibt verschiedene <em>Skalen</em> über die Merkmale definiert sein können. Die am häufigsten verwendete Skalendefinition geht auf Steven zurück und ist auch als <em>Steven’s Levels of Measurements</em>, bzw. <em>NOIR</em>-Skalen bekannt <a class="footnote-reference brackets" href="#stevens" id="id4">4</a>. NOIR ist ein Akronym für die vier Arten von Skalen: Nominal, Ordinal, Intervall, und Rational.</p>
<table class="colwidths-auto table" id="tbl-scales">
<caption><span class="caption-number">Table 3.1 </span><span class="caption-text">Skalen für Merkmale.</span><a class="headerlink" href="#tbl-scales" title="Permalink to this table">¶</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>Skala</p></th>
<th class="head"><p>Eigenschaft</p></th>
<th class="head"><p>Erlaubte Operationen</p></th>
<th class="head"><p>Beispiel</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Nominal</p></td>
<td><p>Klassifikation oder Zugehörigkeit</p></td>
<td><p><span class="math notranslate nohighlight">\(=, \neq\)</span></p></td>
<td><p>Farben als Schwarz, Weiß und Blau.</p></td>
</tr>
<tr class="row-odd"><td><p>Ordinal</p></td>
<td><p>Vergleichbare Level</p></td>
<td><p><span class="math notranslate nohighlight">\(=, \neq, &gt;, &lt;\)</span></p></td>
<td><p>Größe in Small, Medium und Large</p></td>
</tr>
<tr class="row-even"><td><p>Intervall</p></td>
<td><p>Unterschiede und Abstände</p></td>
<td><p><span class="math notranslate nohighlight">\(=, \neq, &gt;, &lt;, + ,-\)</span></p></td>
<td><p>Daten, Temperaturen</p></td>
</tr>
<tr class="row-odd"><td><p>Rational</p></td>
<td><p>Absolute Größen und Mengen</p></td>
<td><p><span class="math notranslate nohighlight">\(=, \neq, &gt;, &lt;, +, -, *, /\)</span></p></td>
<td><p>Größe in cm, Dauer in Sekunden</p></td>
</tr>
</tbody>
</table>
<p><a class="reference internal" href="#tbl-scales"><span class="std std-numref">Table 3.1</span></a> fasst die Eigenschaften der SKalen zusammen.  Nominale und ordinale Merkmale nennt man auch <em>kategorische</em> Merkmale, da sie ihre Werte in Kategorien darstellen. Bei nominalen Merkmalen gibt es keine Ordnung der Kategorien, das heißt, dass man zum Beispiel nicht sagen kann welche Kategorie größer oder kleiner ist. Bei ordinalen Merkmalen gibt es eine wohldefinierte Ordnung, wir können die Kategorien also sortieren. Der Abstand zwischen den Kategorien ist nicht bekannt und auch nicht notwendigerweise gleich zwischen benachbarten Kategorien. Entsprechend kann man nur sagen, dass T-Shirts der Größe <em>Small</em> kleiner sind als <em>Medium</em> und <em>Medium</em> wiederum kleiner als <em>Large</em>. Aber wie groß der Unterschied zwischen <em>Small</em> und <em>Medium</em> ist, und ob der Unterschied zwischen <em>Medium</em> und <em>Large</em> gleich groß sind, ist nicht bekannt. Dieses Wissen hat man erst, wenn man eine Intervallskala verwendet, auf der man die Unterschiede quantifizieren kann. Wir können zum Temperaturdifferenz von 10° C und 5° C berechnen. Was jedoch auf Intervalskalen keinen Sinn ergibt, sind Verhältnisse. Man kann zum Beispiel nicht Sinnvoll sagen, dass dass das Datum 2000-01-01 doppelt so hoch ist wie 1000-01-01. Daher kann man Verhältnisse nur bei Merkmalen mit einer rationalen Skala sinnvoll berechnen. Wenn wir zum Beispiel die Zeit messen, die im Gregorianischen Kalender seit dem Jahr 0 vergangen ist, kann man durchaus sagen das 2000 Jahre unterschied doppelt so viel ist wie 1000 Jahre.</p>
<p>Viele Algorithmen gehen davon aus, dass die Merkmale durch Zahlen repräsentiert werden. Während das auf Intervall- und Rationalskalen kein Problem ist, sind Nominal- und Ordinalskalen nicht numerisch. Ein einfacher Ansatz wäre es die Kategorien einfach durchzunummerieren, zum Beispiel Schwarz als eins, Weiß als zwei und Blau als drei. Diesen Ansatz sollte man jedoch in der Regel vermeiden, da die Gefahr besteht das Algorithmen dann mit diesen Zahlen rechnen und zum Beispiel Differenzen bilden. Dann wäre Blau Minus Weiß auf einmal Schwarz, was natürlich keinen Sinn ergibt. Eine bessere Lösung ist daher das <em>One-Hot Encoding</em>. Das Konzept hinter dem One-Hot Encoding ist eine Nominal-, bzw. Ordinalskala durch viele Merkmale mit den Werten null und eins zu ersetzen. Für jede Kategorie der ursprünglichen Skala gibt es ein neues Merkmal. Für einen Datenpunkt ist der Wert dieses neuen Merkmals eins, wenn der Datenpunkt zur entsprechenden Kategorie gehört und ansonsten null.</p>
<p>Als Beispiel betrachten wir die Nominalskala mit den Werten Schwarz, Weiß, und Blau, es gilt also <span class="math notranslate nohighlight">\(x \in \{Schwarz, Wei\text{ß}, Blau\}\)</span>. Wir ersetzen dieses Feature durch drei neue Feature <span class="math notranslate nohighlight">\(x^{Schwarz}, x^{Wei\text{ß}}, x^{Blaub} \in \{0,1\}\)</span>. Die Werte der neuen Merkmale sind definiert als</p>
<div class="math notranslate nohighlight">
\[\begin{split}x^{Schwarz} = \begin{cases}1 &amp; \text{wenn}~x=\text{Schwarz} \\ 0 &amp; \text{sonst}\end{cases}\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}x^{Wei\text{ß}} = \begin{cases}1 &amp; \text{wenn}~x=\text{Wei\text{ß}} \\ 0 &amp; \text{sonst}\end{cases}\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}x^{Blau} =  \begin{cases}1 &amp; \text{wenn}~x=\text{Blau}  \\ 0 &amp; \text{sonst}\end{cases}\end{split}\]</div>
<p>Mit diesem Ansatz transformiert man also <span class="math notranslate nohighlight">\(n\)</span> Kategorien in <span class="math notranslate nohighlight">\(n\)</span> neue Merkmale. Es ist auch möglich ein One-Hot Encoding mit <span class="math notranslate nohighlight">\(n-1\)</span> neuen Merkmalen zu definieren. Wir könnten im Beispiel einfach <span class="math notranslate nohighlight">\(x^{Blau}\)</span> weglassen und wüssten trotzdem noch eindeutig, welche Farbe es ist: Wenn <span class="math notranslate nohighlight">\(x^{Schwarz} = x^{Wei\text{ß}} = 0\)</span> gilt, muss die Farbe stattdessen Blau sein. Diese Eigenschaft sollte man insbesondere dann ausnutzen, wenn man eine Skala mit zwei Kategorien umwandelt.</p>
<p>Bitte beachten Sie, dass One-Hot Encoding möglicherweise nicht gut funktioniert, wenn sie sehr viele verschiedene Kategorien haben. Dies führt zu vielen neuen Merkmalen, welches bei der anschließenden Modellierung zum Problem werden kann. Hinzu kommt, dass man bei der Umwandlung von Ordinalskalen die Informationen über die Ordnung verliert. In solchen Fällen sollte man nach Möglichkeit auch Analysemethoden zurückgreifen, die direkt mit Nominal-, bzw. Ordinalskalen arbeiten können.</p>
</div>
<div class="section" id="trainings-und-testdaten">
<h2><span class="section-number">3.4. </span>Trainings- und Testdaten<a class="headerlink" href="#trainings-und-testdaten" title="Permalink to this headline">¶</a></h2>
<p>Daten sind das Herz von jedem Data Science Projekt. Die Daten bestehen aus <em>Instanzen</em> von <em>Merkmalen</em>, wobei eine Instanz die Representation eines Objekts der realen Welt durch seine Merkmale ist. <a class="reference internal" href="#tbl-data"><span class="std std-numref">Table 3.2</span></a> zeigt uns ein Beispiel von Daten.</p>
<table class="colwidths-auto table" id="tbl-data">
<caption><span class="caption-number">Table 3.2 </span><span class="caption-text">Beispiel für Instanzen von Objekten mit ihren Merkmalen.</span><a class="headerlink" href="#tbl-data" title="Permalink to this table">¶</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>Form</p></th>
<th class="head"><p>Farbe oben</p></th>
<th class="head"><p>Farbe unten</p></th>
<th class="head"><p>Hintergrundfarbe</p></th>
<th class="head"><p>Flossen</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Oval</p></td>
<td><p>Schwarz</p></td>
<td><p>Weiß</p></td>
<td><p>Blau</p></td>
<td><p>Ja</p></td>
</tr>
<tr class="row-odd"><td><p>Rechteck</p></td>
<td><p>Braun</p></td>
<td><p>Braun</p></td>
<td><p>Grün</p></td>
<td><p>Nein</p></td>
</tr>
<tr class="row-even"><td><p>…</p></td>
<td><p>…</p></td>
<td><p>…</p></td>
<td><p>…</p></td>
<td><p>…</p></td>
</tr>
</tbody>
</table>
<p>Jede Zeile in der Tabelle ist eine Instanz, jede Spalte beinhaltet wie Werte von einem Merkmal. Häufig gibt es noch eine gewissen Eigenschaft die man aus den Merkmalen lernen möchte, sozusagen einen <em>Wert von Interesse</em> der mit jeder Instanz verbunden wird. <a class="reference internal" href="#tbl-data-label"><span class="std std-numref">Table 3.3</span></a> zeigt die Erweiterung der Instanzen.</p>
<table class="colwidths-auto table" id="tbl-data-label">
<caption><span class="caption-number">Table 3.3 </span><span class="caption-text">Beispiel für Instanzen von Objekten mit ihren Merkmalen mit Werten von Interesse. Diese werden häufig auch als <em>Label</em> bezeichnet.</span><a class="headerlink" href="#tbl-data-label" title="Permalink to this table">¶</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>Form</p></th>
<th class="head"><p>Farbe oben</p></th>
<th class="head"><p>Farbe unten</p></th>
<th class="head"><p>Hintergrundfarbe</p></th>
<th class="head"><p>Flossen</p></th>
<th class="head"><p>Wert von Interesse</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Oval</p></td>
<td><p>Schwarz</p></td>
<td><p>Weiß</p></td>
<td><p>Blau</p></td>
<td><p>Ja</p></td>
<td><p>Wal</p></td>
</tr>
<tr class="row-odd"><td><p>Rechteck</p></td>
<td><p>Braun</p></td>
<td><p>Braun</p></td>
<td><p>Grün</p></td>
<td><p>Nein</p></td>
<td><p>Bär</p></td>
</tr>
<tr class="row-even"><td><p>…</p></td>
<td><p>…</p></td>
<td><p>…</p></td>
<td><p>…</p></td>
<td><p>…</p></td>
<td><p>…</p></td>
</tr>
</tbody>
</table>
<p>Je nachdem ob dieser Wert bekannt ist und für die Erstellung eines Modells verwendet wird oder nicht, spricht man vom <em>überwachten</em>, bzw. <em>unüberwachten Lernen</em> (engl. <em>supervised/unsupersized</em>).</p>
<p>Daten sind häufig in Form von Datensätzen organisiert. In diesem Zusammenhang sind die Begriffe <em>Trainingsdaten</em> und <em>Testdaten</em> für die Datenanalyse besonders wichtig. Die Trainingsdaten werden für die Erstellung von Modellen benutzt, das heißt für alles von der Datenexploration, über die Bestimmung von geeigneten Modellen, als auch für Experimente um das beste Modell auszuwählen. Man kann die Trainingsdaten so oft man will benutzt und beliebig transformieren.</p>
<p>Die Testdaten werden jedoch idealerweise nur ein einziges Mal verwendet, und zwar am Ende des Projekts um zu überprüfen ob die Ergebnisse von den Trainingsdaten auch auf andere Daten verallgemeinern und um hierdurch abzuschätzen wie gut ein Modell im operationellen Betrieb funktionieren würde. Hierzu wird das auf den Trainingsdaten ermittelte Modell mit den Testdaten gefüttert um die Güte, basierend auf den in der Discovery definierten Kriterien, zu messen.</p>
<p>Die Unterscheidung zwischen Trainings- und Testdaten ist wichtig um sicherzustellen das man <em>Overfitting</em> verhindert und stattdessen die <em>Generalisierung</em> sicherstellt. Overfitting bedeutet, dass das Modell die Daten auswendig lernt, statt das eigentliche Problem zu lösen. Es ist nämlich relativ einfach ein perfektes Modell für die Trainingsdaten zu erstellen: Man lernt diese einfach auswendig und gibt diese später wieder aus. Bei beliebigen anderen Daten würde dieses Modell jedoch nicht mehr funktionieren. Die Testdaten verhindern genau das. Wenn das Modell nur auswendig gelernt hat statt Zusammenhänge zu erkennen, wird es auf den Testdaten nicht gut funktionieren. Andersrum gilt aber auch, dass wenn ein Modell auch auf den Testdaten gute Ergebnisse liefert, dass es wahrscheinlich ist das es auch in der realen Anwendung wie gewünscht funktioniert.</p>
<p>Leider sind Daten häufig eine nur begrenzt verfügbare Ressource, da das Sammeln von Daten häufig zeitaufwendig und/oder kostenintensiv ist. Auf der einen Seite wissen wir, dass maschinelles Lernen bessere Ergebnisse liefert, wenn mehr Daten zur Verfügung stehen. Auf der anderen Seite ist die Bewertung der Güte auf den Testdaten  genauer, wenn mehr Testdaten zur Verfügung stehen. Wie viele und welche Daten fürs Testen verwendend werden ist also immer eine Abwägung die innerhalb von einem Projekt gemacht werden muss. Im Idealfall stehen genug Daten zur Verfügung, dass man mit <em>Hold-Out</em> Daten arbeiten kann. Das bedeutet man hat einen echten Testdatensatz, der auch nur zu diesem Zweck verwendet wird. Wie viele Daten als Hold-Out-Daten genutzt werden legt man üblicherweise als Prozentsatz der zur Verfügung stehenden Daten fest, zum Beispiel</p>
<ul class="simple">
<li><p>50% Trainingsdaten, 50% Testdaten,</p></li>
<li><p>66,6% Trainingsdaten, 33,4% Testdaten, oder auch</p></li>
<li><p>75% Trainingsdaten, 25% Testdaten.</p></li>
</ul>
<p>Es kann auch Sinn machen, zusätzlich noch <em>Validationsdaten</em> zu nutzen. Validationsdaten sind “wiederverwendbare Testdaten zur Modellauswahl”. Das heißt, dass man die Daten ähnlich wie die Testdaten verwendet, jedoch nicht nur am Ende des Projekts zur abschließenden Bewertung. Stattdessen kann man diese Daten bereits vorher nutzen, zum Beispiel um verschiedene Modelle miteinander zu vergleichen und oder um Modellparameter zu optimieren. Validationsdaten können ebenfalls als Hold-Out Daten erstellt werden, zum Beispiel mit 50% Trainingsdaten, 25% Validationsdaten und 25% Testdaten.</p>
<p>Für den Fall das nicht genug Daten zu Verfügung stehen um mit Hold-Out Daten zu arbeiten, kann man <em>Kreuzvalidierung</em> (engl. <em>cross-validation</em>) nutzen um die Wahrscheinlichkeit von Overfittung zu reduzieren. Bei der Kreuzvalidierung gibt es keine klare Trennung zwischen Trainings- und Testdaten. Stattdessen werden alle Daten sowohl für das Training, als auch für die Bewertung der Güte benutzt. <a class="reference internal" href="#fig-cv"><span class="std std-numref">Fig. 3.2</span></a> beschreibt die Kreuzvalidierung. Bei <span class="math notranslate nohighlight">\(k\)</span>-Facher Kreuzvalidierung (engl. <span class="math notranslate nohighlight">\(k\)</span>-fold cross-validation) werden die Daten hierfür in <span class="math notranslate nohighlight">\(k\)</span> gleichgroße Partitionen unterteilt. Jede Partition wird einmal für das Testen benutzt und alle anderen Partitionen für das Training.</p>
<div class="figure align-default" id="fig-cv">
<a class="reference internal image-reference" href="../_images/cv-german.png"><img alt="../_images/cv-german.png" src="../_images/cv-german.png" style="width: 800px;" /></a>
<p class="caption"><span class="caption-number">Fig. 3.2 </span><span class="caption-text">Verwendung von Daten zur Kreuzvalidierung.</span><a class="headerlink" href="#fig-cv" title="Permalink to this image">¶</a></p>
</div>
<p>Die Güte wird als arithmetisches Mittel der Güte auf der jeweiligen Testpartition berechnet. Bei der Kreuzvalidierung wird somit jede Instanz der Daten genau einmal in den Testdaten und <span class="math notranslate nohighlight">\(k-1\)</span> mal zum Training verwendet. Die Nachteil der Kreuzvalidierung ist das es keine echten Testdaten gibt. Stattdessen handelt es sich vielmehr um Validierungsdaten. Dennoch verwenden wir hier auch den Begriff Testdaten, da dies in der Literatur üblich ist. Da es keine echte Testdaten gibt ist das Risiko von Overfitting bei der Kreuzvalidierung höher als bei der Verwendung von Hold-Out Daten. Daher sollte man, sofern möglich, Hold-Out Daten verwenden und Kreuzvalidierung nur als Notlösung betrachten.</p>
</div>
<div class="section" id="kategorien-von-algorithmen">
<h2><span class="section-number">3.5. </span>Kategorien von Algorithmen<a class="headerlink" href="#kategorien-von-algorithmen" title="Permalink to this headline">¶</a></h2>
<p>Data Science ist ein vielseitiges Gebiet. Je nach Problemstellung gibt es unterschiedliche Algorithmen, die für ein Projekt geeignet sind.</p>
<ul class="simple">
<li><p><em>Assoziationsregeln</em> befassen sich mit Zusammenhängen zwischen Gegenständen in Transaktionen. Der klassische Anwendungsfall von Assoziationsregeln ist die Vorhersage von Gegenständen, die zu einem Warenkorb noch hinzugefügt werden, basierend auf dem aktuellen Inhalt des Warenkorbs. Wir betrachten den Apriori-Algorithmus zum Bestimmen von Assoziationsregeln in <a class="reference internal" href="kapitel_05.html"><span class="doc std std-doc">Kapitel 5</span></a>.</p></li>
<li><p><em>Clustern</em> beschäftigt sich mit der Suche von Gruppen, also Daten die zueinander ähnlich sind und daher zur selben Gruppe gehören. Wir betrachten den <span class="math notranslate nohighlight">\(k\)</span>-Means Algorithmus, den EM Algorithmus, DBSCAN und Single Linkage Clustern in <a class="reference internal" href="kapitel_06.html"><span class="doc std std-doc">Kapitel 6</span></a>.</p></li>
<li><p><em>Klassifikation</em> behandelt das Zuweisen von Labeln zu Objekten. Wir behandeln den <span class="math notranslate nohighlight">\(k\)</span>-Nearest Neighbor Algorithmus, Entscheidungsbäume, Random Forests, Logistische Regression, Naive Bayes, Support Vector Machines und Neuronale Netze in <a class="reference internal" href="kapitel_07.html"><span class="doc std std-doc">Kapitel 7</span></a>.</p></li>
<li><p><em>Regression</em> sucht nach Zusammenhängen zwischen Merkmalen, eventuell mit dem Ziel einen numerischen Wert vorherzusagen. Wir beschäftigen uns mit der linearen Regression durch Ordinary Least Squares (OLS), Ridge, Lasso, und das Elastic Net in <a class="reference internal" href="kapitel_08.html"><span class="doc std std-doc">Kapitel 8</span></a>.</p></li>
<li><p><em>Zeitreihenanalyse</em> berücksichtig die zeitliche Struktur von Daten, zum Beispiel bei täglichen, wöchentlichen, oder monatlichen Daten. Die Zeitreihenanalyse geht über die Regression hinaus, da auch Aspekte wie die Saisonalität berücksichtig werden. Wir betrachten ARIMA in <a class="reference internal" href="kapitel_09.html"><span class="doc std std-doc">Kapitel 9</span></a>.</p></li>
<li><p><em>Text Mining</em> befasst sich mit der Analyse von unstrukturierten textuellen Daten. Grundsätzlich können alle Arten von Algorithmen zum Textmining verwendet werden. Die Schwierigkeit liegt darin, eine geeignete Struktur für den Text zu finden und die Daten zu verarbeiten. Wir betrachten ein einfaches Text Mining Verfahren basierend auf einem Bag-of-Words in <a class="reference internal" href="kapitel_10.html"><span class="doc std std-doc">Kapitel 10</span></a>.</p></li>
</ul>
<p>Bei der Suche nach Assoziationsregeln und beim Clustern werden unüberwachte Lernverfahren, die Anhand der Merkmale nach Mustern in den Daten suchen, verwendet. Daher werden solche Verfahren auch manchmal als Musterkennung (engl. <em>pattern recognition</em>) bezeichnet. Klassifikation, Regression, und Zeitreihenanalyse sind Beispiele für überwachtes Lernen. Das heißt, dass man für diese Ansätze den Wert von Interesse kennen muss und die Verfahren den Zusammenhang zu den Merkmalen lernen.</p>
</div>
<div class="section" id="ubung">
<h2><span class="section-number">3.6. </span>Übung<a class="headerlink" href="#ubung" title="Permalink to this headline">¶</a></h2>
<p>In der ersten Übung machen wir uns mit dem Arbeiten mit Merkmalen in Python durch <em>Dataframes</em> vertraut. Hierbei lernen wir Daten zu laden und zu filtern. Für diese Übung müssen Sie eigenständig die benötigten Funktionen aus der Programmbibliothek <code class="docutils literal notranslate"><span class="pre">pandas</span></code> raussuchen <a class="footnote-reference brackets" href="#pandas" id="id5">5</a>. Sollten Sie wenig Erfahrung mit Python (oder Programmierung) haben, können diese Übung auch überspringen und sich stattdessen an den Quelltextbeispielen der folgenden Kapitel orientieren. Sie sollten sich aber in jedem Fall zumindest die Aufgaben durchlesen, da dass Konzept der Dataframes erklärt wird.</p>
<div class="section" id="laden-von-csv-daten">
<h3><span class="section-number">3.6.1. </span>Laden von CSV Daten<a class="headerlink" href="#laden-von-csv-daten" title="Permalink to this headline">¶</a></h3>
<p>Oft liegen Daten als CSV Dateien vor. Die erste Zeile beinhaltet die Namen der Merkmale, die folgenden Zeilen jeweils die Werte einer Instanz. Laden Sie sich zuerst und uns angepasste Daten über Insolvenzen runter <a class="footnote-reference brackets" href="#our-bankruptcy" id="id6">6</a>. Das original finden Sie im <em>UCI Archive</em> <a class="footnote-reference brackets" href="#usi" id="id7">7</a>, einer großen Sammlung von Beispieldatensätzen für maschinelles Lernen. Wir haben diese Daten angepasst, in dem wir die Werte einiger Merkmale gelöscht haben.</p>
<p>Laden Sie die CSV Datei in einen <em>Dataframe</em> mit Hilfe der Bibliothek <code class="docutils literal notranslate"><span class="pre">pandas</span></code>. Dataframes sind ähnlich zu Matrizen. Es gibt jedoch einige wesentliche Unterschiede:</p>
<ul class="simple">
<li><p>Dataframes können einfacher verändert werden, in dem man Zeilen/Spalten entfernt.</p></li>
<li><p>Die Zeilen und Spalten von den Dataframes können benannet sein, werden also nicht nur mit Hilfe ihres numerischen Indexes identifiziert.</p></li>
<li><p>Jede Spalte kann einen anderen Typ haben. Eine Spalte könnte zum Beispiel Zeichenketten beinhalten und eine andere Gleitkommazahlen.</p></li>
</ul>
<p>Nachdem die Daten geladen sind, geben sie einige Informationen über die Daten aus:</p>
<ul class="simple">
<li><p>Wie viele Instanzen gibt es?</p></li>
<li><p>Wie viele Merkmale gibt es?</p></li>
<li><p>Was sind die Namen der Merkmale?</p></li>
</ul>
</div>
<div class="section" id="entfernen-von-merkmalen">
<h3><span class="section-number">3.6.2. </span>Entfernen von Merkmalen<a class="headerlink" href="#entfernen-von-merkmalen" title="Permalink to this headline">¶</a></h3>
<p>Entfernen Sie das Merkmal <code class="docutils literal notranslate"><span class="pre">Company</span></code>.</p>
</div>
<div class="section" id="entfernen-von-instanzen-mit-fehlenden-werten">
<h3><span class="section-number">3.6.3. </span>Entfernen von Instanzen mit fehlenden Werten<a class="headerlink" href="#entfernen-von-instanzen-mit-fehlenden-werten" title="Permalink to this headline">¶</a></h3>
<p>Entfernen Sie alle Instanzen, bei denen ein Wert fehlt. Die fehlenden Werte sind als <code class="docutils literal notranslate"><span class="pre">NA</span></code> in der CSV Datei markiert. Hierdurch sollten fünf Instanzen entfernt werden.</p>
</div>
<div class="section" id="rechnen-mit-dataframes">
<h3><span class="section-number">3.6.4. </span>Rechnen mit Dataframes<a class="headerlink" href="#rechnen-mit-dataframes" title="Permalink to this headline">¶</a></h3>
<p>Man mit Dataframes einfach rechnen. Ergänzen Sie zwei Spalten mit den Ergebnissen folgender Berechnungen:</p>
<ul class="simple">
<li><p>Die Summe der Spalten <code class="docutils literal notranslate"><span class="pre">WC/TA</span></code> und <code class="docutils literal notranslate"><span class="pre">RE/TA</span></code>.</p></li>
<li><p>Das Produkt der Spalten <code class="docutils literal notranslate"><span class="pre">EBIT/TA</span></code> und <code class="docutils literal notranslate"><span class="pre">S/TA</span></code>.</p></li>
</ul>
</div>
<div class="section" id="zusammenfugen-von-dataframes">
<h3><span class="section-number">3.6.5. </span>Zusammenfügen von Dataframes<a class="headerlink" href="#zusammenfugen-von-dataframes" title="Permalink to this headline">¶</a></h3>
<p>Laden Sie die Daten ein zweites Mal aus der CSV Datei. Vereinigen sie den Dataframe aus der vorigen Aufgabe mit den neu gelandenen Daten, so dass:</p>
<ul class="simple">
<li><p>Das Merkmal <code class="docutils literal notranslate"><span class="pre">Company</span></code> wieder Teil des neuen Dataframes ist.</p></li>
<li><p>Die Instanzen mit fehlenden Werten weiterhin entfernt sind.</p></li>
<li><p>Die berechneten Merkmale (Summe, Produkt) Teil des neuen Dataframes sind.</p></li>
</ul>
</div>
<div class="section" id="auswahl-von-teilmengen">
<h3><span class="section-number">3.6.6. </span>Auswahl von Teilmengen<a class="headerlink" href="#auswahl-von-teilmengen" title="Permalink to this headline">¶</a></h3>
<p>Nutzen den zusammgenfügten Dataframe um Teilmengen der Instanzen und Merkmale zu bestimmen.</p>
<ul class="simple">
<li><p>Die Instanzen 10 bis 20 und alle Merkmale.</p></li>
<li><p>Die Merkmale in den ersten vier Spalten und alle Instanzen.</p></li>
<li><p>Die Merkmale <code class="docutils literal notranslate"><span class="pre">WC/TA</span></code> und <code class="docutils literal notranslate"><span class="pre">EBIT/TA</span></code> und alle Instanzen.</p></li>
<li><p>Alle Merkmale und nur die Instanzen, bei denen <code class="docutils literal notranslate"><span class="pre">RE/TA</span></code> kleiner als -20 ist.</p></li>
<li><p>Alle Merkmale und nur die Instanzen, bei denen <code class="docutils literal notranslate"><span class="pre">RE/RA</span></code> kleiner als -20 ist und <code class="docutils literal notranslate"><span class="pre">bankrupt</span></code> null ist.</p></li>
<li><p>Nur die Merkmale <code class="docutils literal notranslate"><span class="pre">WC/TA</span></code> und <code class="docutils literal notranslate"><span class="pre">EBIT/TA</span></code> und nur die Instanzen, bei denen <code class="docutils literal notranslate"><span class="pre">RE/RA</span></code> kleiner als -20 ist und <code class="docutils literal notranslate"><span class="pre">bankrupt</span></code> null ist.</p></li>
</ul>
<hr class="footnotes docutils" />
<dl class="footnote brackets">
<dt class="label" id="nfl"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p><a class="reference external" href="https://doi.org/10.1109/4235.585893">https://doi.org/10.1109/4235.585893</a></p>
</dd>
<dt class="label" id="mitchel"><span class="brackets"><a class="fn-backref" href="#id2">2</a></span></dt>
<dd><p><a class="reference external" href="https://doi.org/10.1007/978-3-662-12405-5">https://doi.org/10.1007/978-3-662-12405-5</a></p>
</dd>
<dt class="label" id="alphazero"><span class="brackets"><a class="fn-backref" href="#id3">3</a></span></dt>
<dd><p><a class="reference external" href="https://arxiv.org/abs/1712.01815">https://arxiv.org/abs/1712.01815</a></p>
</dd>
<dt class="label" id="stevens"><span class="brackets"><a class="fn-backref" href="#id4">4</a></span></dt>
<dd><p><a class="reference external" href="https://doi.org/10.1126/science.103.2684.677">https://doi.org/10.1126/science.103.2684.677</a></p>
</dd>
<dt class="label" id="pandas"><span class="brackets"><a class="fn-backref" href="#id5">5</a></span></dt>
<dd><p><a class="reference external" href="https://pandas.pydata.org/">https://pandas.pydata.org/</a></p>
</dd>
<dt class="label" id="our-bankruptcy"><span class="brackets"><a class="fn-backref" href="#id6">6</a></span></dt>
<dd><p><a class="reference external" href="https://data-science-crashkurs.de/exercises/data/analcatdata_bankruptcy.csv">https://data-science-crashkurs.de/exercises/data/analcatdata_bankruptcy.csv</a></p>
</dd>
<dt class="label" id="usi"><span class="brackets"><a class="fn-backref" href="#id7">7</a></span></dt>
<dd><p><a class="reference external" href="https://archive.ics.uci.edu/ml/index.php">https://archive.ics.uci.edu/ml/index.php</a></p>
</dd>
</dl>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./chapters"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="kapitel_02.html" title="previous page"><span class="section-number">2. </span>Der Prozess von Data Science Projekten</a>
    <a class='right-next' id="next-link" href="kapitel_04.html" title="next page"><span class="section-number">4. </span>Erkunden der Daten</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Steffen Herbold<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>